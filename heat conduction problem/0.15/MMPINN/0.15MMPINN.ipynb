{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44a1c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c80214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "np.random.seed(1232)\n",
    "tf.set_random_seed(1232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b063bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x0, u0, tb, X_f, layers, lb, ub,u_lb,u_ub):\n",
    "        \n",
    "        #    lb = np.array([-1, 0])      ub = np.array([1, 1])\n",
    "        \n",
    "        X0 = np.concatenate((x0, 0*x0+0.0), 1)              #    初始     \n",
    "        X_lb = np.concatenate((0*tb + lb[0], tb), 1)    #    边界-1\n",
    "        X_ub = np.concatenate((0*tb + ub[0], tb), 1)    #    边界+1    \n",
    "        \n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "               \n",
    "        self.x0 = X0[:,0:1]\n",
    "        self.t0 = X0[:,1:2]\n",
    "\n",
    "        self.x_lb = X_lb[:,0:1]\n",
    "        self.t_lb = X_lb[:,1:2]\n",
    "        self.hsadasjd=1\n",
    "\n",
    "        self.x_ub = X_ub[:,0:1]\n",
    "        self.t_ub = X_ub[:,1:2]\n",
    "        \n",
    "        self.x_f = X_f[:,0:1]\n",
    "        self.t_f = X_f[:,1:2]\n",
    "        self.u_lb=u_lb\n",
    "        self.u_ub=u_ub\n",
    "        #分别是初始时刻的实部和虚部\n",
    "        self.u0 = u0\n",
    "        self.losslossloss=[]\n",
    "        # Initialize NNs\n",
    "        self.layers = layers\n",
    "        #返回初始的权重w和偏差b\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        # tf Placeholders\n",
    "        #形参 占位符，行数不确定，列数确定为1\n",
    "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, self.x0.shape[1]])\n",
    "        self.t0_tf = tf.placeholder(tf.float32, shape=[None, self.t0.shape[1]])\n",
    "        self.u_lb_tf = tf.placeholder(tf.float32, shape=[None, self.u_lb.shape[1]])\n",
    "        self.u_ub_tf = tf.placeholder(tf.float32, shape=[None, self.u_ub.shape[1]])\n",
    "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, self.u0.shape[1]])\n",
    "        self.x_lb_tf = tf.placeholder(tf.float32, shape=[None, self.x_lb.shape[1]])\n",
    "        self.t_lb_tf = tf.placeholder(tf.float32, shape=[None, self.t_lb.shape[1]])\n",
    "        self.x_ub_tf = tf.placeholder(tf.float32, shape=[None, self.x_ub.shape[1]])\n",
    "        self.t_ub_tf = tf.placeholder(tf.float32, shape=[None, self.t_ub.shape[1]])\n",
    "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
    "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, self.t_f.shape[1]])\n",
    "\n",
    "        # tf Graphs  进行预测\n",
    "        self.u0_pred= self.net_uv(self.x0_tf, self.t0_tf)\n",
    "        self.u_lb_pred= self.net_uv(self.x_lb_tf, self.t_lb_tf)\n",
    "        self.u_ub_pred = self.net_uv(self.x_ub_tf, self.t_ub_tf)\n",
    "        self.f_u_pred= self.net_f_uv(self.x_f_tf, self.t_f_tf)\n",
    "        \n",
    "        # Loss   8个损失函数相加\n",
    "        self.loss3=tf.pow(tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)),1/1)\n",
    "        \n",
    "        self.loss2=tf.pow(tf.reduce_mean(tf.square(self.f_u_pred)),1/1)\n",
    "                \n",
    "        \n",
    "        self.loss = tf.pow(tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)),1)+                     tf.pow((tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +                     tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))),1) +                     tf.pow(tf.reduce_mean(tf.square(self.f_u_pred)),1/3)   \n",
    "        self.lossss = tf.pow(tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)),1)+                     tf.pow((tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +                     tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))),1) +                     tf.pow(tf.reduce_mean(tf.square(self.f_u_pred)),1/2)  \n",
    "        self.lossss33 = tf.pow(tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)),1)+                     tf.pow((tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +                     tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))),1) +                     tf.pow(tf.reduce_mean(tf.square(self.f_u_pred)),1)  \n",
    "                        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.loss4 = tf.pow((tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +                     tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))),1/1)\n",
    "        \n",
    "        \n",
    "        # Optimizers  maxiter最大迭代次数  maxfun最大求值次数 maxcor int变量的最大数量\n",
    "        #maxls 可选的最大搜索步数\n",
    "        #maxls 可选的最大搜索步数\n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 100000,\n",
    "                                                                           'maxfun': 100000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.optimizer11 = tf.contrib.opt.ScipyOptimizerInterface(self.lossss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 100000,\n",
    "                                                                           'maxfun': 100000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "        \n",
    "        self.optimizer22 = tf.contrib.opt.ScipyOptimizerInterface(self.lossss33, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 100000,\n",
    "                                                                           'maxfun': 100000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        是一个寻找全局最优点的优化算法，引入了二次方梯度校正\n",
    "        除了利用反向传播算法对权重和偏置项进行修正外，也在运行中不断修正学习率。\n",
    "        根据其损失量学习自适应，损失量大则学习率大，进行修正的角度越大，损失量小，修正的幅度也小，学习率就小，\n",
    "        但是不会超过自己所设定的学习率。20\n",
    "        3\n",
    "        '''\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "                \n",
    "        # tf session  配置Session运行参数&&GPU设备指定）\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        #初始化模型的参数\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        #产生截断正态分布随机数，stddev是标准差，取值范围为[ 0 - 2 * stddev, 0+2 * stddev ]\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        \n",
    "        #将初始输入X映射到-1到1之间为H\n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "    \n",
    "    def net_uv(self, x, t):\n",
    "        X = tf.concat([x,t],1)\n",
    "        \n",
    "        uv = self.neural_net(X, self.weights, self.biases)\n",
    "\n",
    "\n",
    "        return uv\n",
    "    \n",
    "    \n",
    "    \n",
    "    def net_f_uv(self, x, t):\n",
    "        \n",
    "        u = self.net_uv(x,t)       \n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        \n",
    "        hhhhhh=0.15\n",
    "        f_u = u_t-u_xx-2*tf.exp(1/((2*t-1)*(2*t-1)+hhhhhh))+tf.exp(1/((2*t-1)*(2*t-1)+hhhhhh))*(1-x*x)*4*(2*t-1)/((2*t-1)*(2*t-1)+hhhhhh)/((2*t-1)*(2*t-1)+hhhhhh)\n",
    "        #f_u=u-tf.exp(1/((2*t-1)*(2*t-1)+0.5))*(1-x*x)\n",
    "        #return f_u/1319.919299519142\n",
    "        return f_u\n",
    "    \n",
    "    def callback(self, loss,f_u_pred,u0_pred,u_ub_pred,u_lb_pred):\n",
    "        \n",
    "        self.losslossloss.append(loss)\n",
    "            #losslossloss2\n",
    "        sss=self.hsadasjd\n",
    "        if sss%20==0:\n",
    "            losssss =tf.reduce_mean(tf.square(f_u_pred))\n",
    "            array1 = losssss.eval(session=tf.Session())        \n",
    "            tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        \n",
    "            loss1123456=self.u0_tf\n",
    "            lossskdajsdkas=self.sess.run(loss1123456, tf_dict)\n",
    "            zkjxJXhz = tf.reduce_mean(tf.square(lossskdajsdkas - u0_pred))\n",
    "            array2 = zkjxJXhz.eval(session=tf.Session())\n",
    "        \n",
    "            loss1123456=self.u_ub_tf\n",
    "            lssss1=self.sess.run(loss1123456, tf_dict)\n",
    "            loss112345sds6=self.u_lb_tf\n",
    "            sadsk=self.sess.run(loss112345sds6, tf_dict)            \n",
    "            \n",
    "            zkjxJXhzs = tf.reduce_mean(tf.square( lssss1- u_ub_pred))+tf.reduce_mean(tf.square(sadsk  - u_lb_pred))\n",
    "            array4 = zkjxJXhzs.eval(session=tf.Session())\n",
    "            print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e' % \n",
    "                      (sss,array2,array4,array1))\n",
    "            \n",
    "            log5=open(\"log5.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array2,file=log5)\n",
    "            log5.close() \n",
    "            log6=open(\"log6.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array4,file=log6)\n",
    "            log6.close()            \n",
    "            log7=open(\"log7.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array1,file=log7)\n",
    "            log7.close()                \n",
    "            \n",
    "            \n",
    "            \n",
    "        sss=sss+1\n",
    "        self.hsadasjd=sss\n",
    "    \n",
    "    \n",
    "    def callback11(self, lossss,f_u_pred,u0_pred,u_ub_pred,u_lb_pred):\n",
    "        \n",
    "        self.losslossloss.append(lossss)\n",
    "            #losslossloss2\n",
    "        sss=self.hsadasjd\n",
    "        if sss%20==0:\n",
    "            losssss =tf.reduce_mean(tf.square(f_u_pred))\n",
    "            array1 = losssss.eval(session=tf.Session())        \n",
    "            tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        \n",
    "            loss1123456=self.u0_tf\n",
    "            lossskdajsdkas=self.sess.run(loss1123456, tf_dict)\n",
    "            zkjxJXhz = tf.reduce_mean(tf.square(lossskdajsdkas - u0_pred))\n",
    "            array2 = zkjxJXhz.eval(session=tf.Session())\n",
    "        \n",
    "            loss1123456=self.u_ub_tf\n",
    "            lssss1=self.sess.run(loss1123456, tf_dict)\n",
    "            loss112345sds6=self.u_lb_tf\n",
    "            sadsk=self.sess.run(loss112345sds6, tf_dict)            \n",
    "            \n",
    "            zkjxJXhzs = tf.reduce_mean(tf.square( lssss1- u_ub_pred))+tf.reduce_mean(tf.square(sadsk  - u_lb_pred))\n",
    "            array4 = zkjxJXhzs.eval(session=tf.Session())\n",
    "            print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e' % \n",
    "                      (sss,array2,array4,array1))\n",
    "        sss=sss+1\n",
    "        self.hsadasjd=sss    \n",
    "    \n",
    "    \n",
    "    def callback22(self, lossss33,f_u_pred,u0_pred,u_ub_pred,u_lb_pred):\n",
    "        \n",
    "        self.losslossloss.append(lossss33)\n",
    "            #losslossloss2\n",
    "        sss=self.hsadasjd\n",
    "        if sss%20==0:\n",
    "            losssss =tf.reduce_mean(tf.square(f_u_pred))\n",
    "            array1 = losssss.eval(session=tf.Session())        \n",
    "            tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        \n",
    "            loss1123456=self.u0_tf\n",
    "            lossskdajsdkas=self.sess.run(loss1123456, tf_dict)\n",
    "            zkjxJXhz = tf.reduce_mean(tf.square(lossskdajsdkas - u0_pred))\n",
    "            array2 = zkjxJXhz.eval(session=tf.Session())\n",
    "        \n",
    "            loss1123456=self.u_ub_tf\n",
    "            lssss1=self.sess.run(loss1123456, tf_dict)\n",
    "            loss112345sds6=self.u_lb_tf\n",
    "            sadsk=self.sess.run(loss112345sds6, tf_dict)            \n",
    "            \n",
    "            zkjxJXhzs = tf.reduce_mean(tf.square( lssss1- u_ub_pred))+tf.reduce_mean(tf.square(sadsk  - u_lb_pred))\n",
    "            array4 = zkjxJXhzs.eval(session=tf.Session())\n",
    "            print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e' % \n",
    "                      (sss,array2,array4,array1))\n",
    "            \n",
    "            log5=open(\"log5.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array2,file=log5)\n",
    "            log5.close() \n",
    "            log6=open(\"log6.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array4,file=log6)\n",
    "            log6.close()            \n",
    "            log7=open(\"log7.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array1,file=log7)\n",
    "            log7.close()            \n",
    "            \n",
    "        sss=sss+1\n",
    "        self.hsadasjd=sss \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self, nIter):   \n",
    "        tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        lossloss1 = []\n",
    "        lossloss2 = []\n",
    "        lossloss3=[]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        loss_value11 = self.sess.run(self.loss3, tf_dict)\n",
    "        lossloss1.append(loss_value11)\n",
    "        \n",
    "        loss_value22 = self.sess.run(self.loss2, tf_dict)\n",
    "        lossloss2.append(loss_value22)\n",
    "        \n",
    "        loss_value33 = self.sess.run(self.loss4, tf_dict)\n",
    "        lossloss3.append(loss_value33)\n",
    "        \n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            # Print\n",
    "            if it % 20== 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                \n",
    "                loss_value11 = self.sess.run(self.loss3, tf_dict)\n",
    "                lossloss1.append(loss_value11)\n",
    "                \n",
    "                loss_value22 = self.sess.run(self.loss2, tf_dict)\n",
    "                lossloss2.append(loss_value22)\n",
    "                \n",
    "                loss_value33 = self.sess.run(self.loss4, tf_dict)\n",
    "                lossloss3.append(loss_value33)\n",
    "                \n",
    "                print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e,Time: %.2f' % \n",
    "                      (it, loss_value11,loss_value33,loss_value22, elapsed))\n",
    "                \n",
    "                start_time = time.time()\n",
    "                log1=open(\"log1.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "                print(loss_value11,file=log1)\n",
    "                log1.close()\n",
    "                log2=open(\"log2.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "                print(loss_value33,file=log2)\n",
    "                log2.close()\n",
    "                log3=open(\"log3.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "                print(loss_value22,file=log3)\n",
    "                log3.close()\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "        self.optimizer.minimize(self.sess, \n",
    "                                feed_dict = tf_dict, \n",
    "                                fetches = [self.loss,self.f_u_pred,self.u0_pred,self.u_ub_pred,self.u_lb_pred], \n",
    "                                loss_callback = self.callback\n",
    "                               )    \n",
    "        \n",
    "        \n",
    "    \n",
    "        self.hsadasjd=1\n",
    "    \n",
    "        self.optimizer11.minimize(self.sess, \n",
    "                                feed_dict = tf_dict, \n",
    "                                fetches = [self.lossss,self.f_u_pred,self.u0_pred,self.u_ub_pred,self.u_lb_pred], \n",
    "                                loss_callback = self.callback\n",
    "                               )  \n",
    "        \n",
    "        \n",
    "      \n",
    "\n",
    "        \n",
    "        self.hsadasjd=1        \n",
    "        \n",
    "        \n",
    "        self.optimizer22.minimize(self.sess, \n",
    "                                feed_dict = tf_dict, \n",
    "                                fetches = [self.lossss33,self.f_u_pred,self.u0_pred,self.u_ub_pred,self.u_lb_pred], \n",
    "                                loss_callback = self.callback\n",
    "                               )         \n",
    "                \n",
    "        return lossloss1,lossloss2\n",
    "    \n",
    "    def predict(self, X_star):\n",
    "        \n",
    "        tf_dict = {self.x0_tf: X_star[:,0:1], self.t0_tf: X_star[:,1:2]}\n",
    "        \n",
    "        u_star = self.sess.run(self.u0_pred, tf_dict)  \n",
    "        \n",
    "        \n",
    "        tf_dict = {self.x_f_tf: X_star[:,0:1], self.t_f_tf: X_star[:,1:2]}\n",
    "        \n",
    "        f_u_star = self.sess.run(self.f_u_pred, tf_dict)\n",
    "               \n",
    "        return u_star,f_u_star\n",
    "    def loss_show(self):\n",
    "        return self.losslossloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b938223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatsolution(x,t):\n",
    "    return math.exp(1/((2*t-1)**2+0.15))*(1-x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbb4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "         \n",
    "    \n",
    "    # Doman bounds\n",
    "    lb = np.array([-1, 0])\n",
    "    ub = np.array([1, 1])\n",
    "\n",
    "    N0 = 1200                                      #初始点\n",
    "    N_b = 1200                                     #边界点\n",
    "    N_f = 10000                                #适配点\n",
    "    layers = [2,50,50,50,50,1]  \n",
    "    #读取真实解\n",
    "    x=np.linspace(-1,1,1200).flatten()[:,None]   \n",
    "    t=np.linspace(0,1,1200).flatten()[:,None]   \n",
    "    res=np.zeros([len(x),len(t)])  \n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(t)):\n",
    "            res[i,j]=heatsolution(x[i],t[j])\n",
    "    \n",
    "    \n",
    "    X, T = np.meshgrid(x, t)\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    #选定初始点N0=700个点\n",
    "    idx_x = np.random.choice(x.shape[0], N0, replace=False)   \n",
    "    x0 = x[idx_x,:]\n",
    "    u0 = res[idx_x,0:1]\n",
    "    #选择N_b=700个边界点\n",
    "    idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "    tb = t[idx_t,:]\n",
    "    u_lb = res[0,idx_t]\n",
    "    u_ub=res[-1,idx_t]\n",
    "    #N_f=2500个随机搭配点   第一列位置 第二列时间\n",
    "    X_f = lb + (ub-lb)*lhs(2, N_f)\n",
    "    x0=np.array(x0).flatten()[:,None]\n",
    "    u0=np.array(u0).flatten()[:,None]\n",
    "    u_lb=np.array(u_lb).flatten()[:,None]\n",
    "    u_ub=np.array(u_ub).flatten()[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44e1cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PhysicsInformedNN(x0, u0,tb, X_f, layers, lb, ub,u_lb,u_ub)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56e164bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss1: 2.311676741e+00,loss2: 4.176654294e-02 Loss3: 4.800281000e+06,Time: 4.55\n",
      "It: 20, Loss1: 9.098256230e-01,loss2: 3.754805624e-01 Loss3: 4.800681500e+06,Time: 1.98\n",
      "It: 40, Loss1: 4.931460619e-01,loss2: 4.473743439e-01 Loss3: 4.800668500e+06,Time: 2.00\n",
      "It: 60, Loss1: 1.300475299e-01,loss2: 2.060327232e-01 Loss3: 4.800451500e+06,Time: 1.97\n",
      "It: 80, Loss1: 4.892706871e-02,loss2: 1.809792221e-02 Loss3: 4.800216000e+06,Time: 1.98\n",
      "It: 100, Loss1: 9.154754691e-03,loss2: 1.316381991e-02 Loss3: 4.799659000e+06,Time: 1.88\n",
      "It: 120, Loss1: 6.205124781e-03,loss2: 1.317783259e-02 Loss3: 4.799546000e+06,Time: 2.03\n",
      "It: 140, Loss1: 5.778168794e-03,loss2: 1.132492628e-02 Loss3: 4.799525500e+06,Time: 1.95\n",
      "It: 160, Loss1: 5.570510402e-03,loss2: 1.038872637e-02 Loss3: 4.799494000e+06,Time: 1.92\n",
      "It: 180, Loss1: 4.914076068e-03,loss2: 1.016537100e-02 Loss3: 4.799445500e+06,Time: 1.92\n",
      "It: 200, Loss1: 4.482519813e-03,loss2: 9.701423347e-03 Loss3: 4.799399000e+06,Time: 1.94\n",
      "It: 220, Loss1: 4.100844264e-03,loss2: 9.239265695e-03 Loss3: 4.799347000e+06,Time: 2.03\n",
      "It: 240, Loss1: 3.718242748e-03,loss2: 8.836491033e-03 Loss3: 4.799285500e+06,Time: 1.92\n",
      "It: 260, Loss1: 3.363717347e-03,loss2: 8.428355679e-03 Loss3: 4.799214500e+06,Time: 1.90\n",
      "It: 280, Loss1: 3.030871507e-03,loss2: 8.015958592e-03 Loss3: 4.799129000e+06,Time: 1.96\n",
      "It: 300, Loss1: 2.717602998e-03,loss2: 7.595486008e-03 Loss3: 4.799028500e+06,Time: 1.92\n",
      "It: 320, Loss1: 2.426159801e-03,loss2: 7.155376486e-03 Loss3: 4.798904500e+06,Time: 1.98\n",
      "It: 340, Loss1: 2.158283489e-03,loss2: 6.682214793e-03 Loss3: 4.798749000e+06,Time: 2.01\n",
      "It: 360, Loss1: 1.915851841e-03,loss2: 6.152017973e-03 Loss3: 4.798551500e+06,Time: 2.01\n",
      "It: 380, Loss1: 1.698513632e-03,loss2: 5.509286188e-03 Loss3: 4.798292000e+06,Time: 1.98\n",
      "It: 400, Loss1: 1.492766780e-03,loss2: 4.582696594e-03 Loss3: 4.797931500e+06,Time: 1.99\n",
      "It: 420, Loss1: 1.210645423e-03,loss2: 2.975753509e-03 Loss3: 4.797375500e+06,Time: 1.92\n",
      "It: 440, Loss1: 8.112590876e-04,loss2: 1.928614220e-03 Loss3: 4.796406000e+06,Time: 1.94\n",
      "It: 460, Loss1: 6.518289447e-04,loss2: 3.922956064e-03 Loss3: 4.794866000e+06,Time: 1.96\n",
      "It: 480, Loss1: 1.072171377e-03,loss2: 7.965245284e-03 Loss3: 4.792595500e+06,Time: 1.93\n",
      "It: 500, Loss1: 2.008950338e-03,loss2: 1.323707029e-02 Loss3: 4.789505500e+06,Time: 1.91\n",
      "It: 520, Loss1: 2.637048252e-03,loss2: 1.553686149e-02 Loss3: 4.784223000e+06,Time: 1.96\n",
      "It: 540, Loss1: 3.167455085e-03,loss2: 1.993228868e-02 Loss3: 4.774462500e+06,Time: 1.96\n",
      "It: 560, Loss1: 4.723790567e-03,loss2: 2.683695778e-02 Loss3: 4.757758000e+06,Time: 2.02\n",
      "It: 580, Loss1: 4.646096844e-03,loss2: 3.216911480e-02 Loss3: 4.733883000e+06,Time: 2.01\n",
      "It: 600, Loss1: 4.097704310e-03,loss2: 3.863073140e-02 Loss3: 4.699869000e+06,Time: 1.95\n",
      "It: 620, Loss1: 5.478219595e-03,loss2: 5.461184680e-02 Loss3: 4.651657000e+06,Time: 1.92\n",
      "It: 640, Loss1: 5.104925949e-03,loss2: 4.870076850e-02 Loss3: 4.596362500e+06,Time: 1.95\n",
      "It: 660, Loss1: 9.160992689e-03,loss2: 7.736377418e-02 Loss3: 4.531502500e+06,Time: 2.02\n",
      "It: 680, Loss1: 6.777063012e-03,loss2: 6.598199904e-02 Loss3: 4.459924500e+06,Time: 1.96\n",
      "It: 700, Loss1: 2.048602886e-02,loss2: 1.005387083e-01 Loss3: 4.382986000e+06,Time: 1.98\n",
      "It: 720, Loss1: 9.227278642e-03,loss2: 9.853789210e-02 Loss3: 4.312733500e+06,Time: 2.00\n",
      "It: 740, Loss1: 9.168243967e-03,loss2: 1.034859717e-01 Loss3: 4.246901000e+06,Time: 1.95\n",
      "It: 760, Loss1: 1.269570831e-02,loss2: 1.035661101e-01 Loss3: 4.184333500e+06,Time: 1.99\n",
      "It: 780, Loss1: 1.247357950e-02,loss2: 1.068378016e-01 Loss3: 4.125806500e+06,Time: 1.98\n",
      "It: 800, Loss1: 1.449313201e-02,loss2: 1.027887240e-01 Loss3: 4.073477750e+06,Time: 1.96\n",
      "It: 820, Loss1: 1.420806535e-02,loss2: 8.170432597e-02 Loss3: 4.027487750e+06,Time: 1.98\n",
      "It: 840, Loss1: 1.838872582e-02,loss2: 3.016300201e-01 Loss3: 3.983423000e+06,Time: 1.99\n",
      "It: 860, Loss1: 1.547780633e-02,loss2: 7.169104367e-02 Loss3: 3.944761000e+06,Time: 2.03\n",
      "It: 880, Loss1: 1.453452744e-02,loss2: 7.031530142e-02 Loss3: 3.906520750e+06,Time: 1.89\n",
      "It: 900, Loss1: 1.573165320e-02,loss2: 2.319761813e-01 Loss3: 3.869819750e+06,Time: 2.46\n",
      "It: 920, Loss1: 1.540846657e-02,loss2: 1.220842004e-01 Loss3: 3.835267000e+06,Time: 2.63\n",
      "It: 940, Loss1: 1.806559972e-02,loss2: 1.884374022e-01 Loss3: 3.803109750e+06,Time: 2.82\n",
      "It: 960, Loss1: 1.580557786e-02,loss2: 9.548343718e-02 Loss3: 3.770803000e+06,Time: 2.71\n",
      "It: 980, Loss1: 4.300704971e-02,loss2: 7.640784979e-01 Loss3: 3.738958750e+06,Time: 2.78\n",
      "It: 1000, Loss1: 1.357263606e-02,loss2: 8.734855801e-02 Loss3: 3.711221000e+06,Time: 2.95\n",
      "It: 1020, Loss1: 1.704967581e-02,loss2: 1.048429236e-01 Loss3: 3.684113500e+06,Time: 2.68\n",
      "It: 1040, Loss1: 1.515930798e-02,loss2: 8.154471964e-02 Loss3: 3.655747250e+06,Time: 2.69\n",
      "It: 1060, Loss1: 1.689649187e-02,loss2: 8.895072341e-02 Loss3: 3.626709000e+06,Time: 2.80\n",
      "It: 1080, Loss1: 3.167559206e-02,loss2: 2.179872990e-01 Loss3: 3.599922750e+06,Time: 3.02\n",
      "It: 1100, Loss1: 2.045208961e-02,loss2: 9.386895597e-02 Loss3: 3.573904250e+06,Time: 2.69\n",
      "It: 1120, Loss1: 5.170748010e-02,loss2: 3.869009912e-01 Loss3: 3.548330000e+06,Time: 2.05\n",
      "It: 1140, Loss1: 2.286552079e-02,loss2: 1.186129600e-01 Loss3: 3.523823250e+06,Time: 2.10\n",
      "It: 1160, Loss1: 1.889731362e-02,loss2: 8.000476658e-02 Loss3: 3.498494000e+06,Time: 1.98\n",
      "It: 1180, Loss1: 1.007928029e-01,loss2: 6.058267355e-01 Loss3: 3.472921000e+06,Time: 2.07\n",
      "It: 1200, Loss1: 3.522628173e-02,loss2: 1.340698302e-01 Loss3: 3.449262500e+06,Time: 2.74\n",
      "It: 1220, Loss1: 2.252614871e-02,loss2: 7.332535088e-02 Loss3: 3.424923750e+06,Time: 2.15\n",
      "It: 1240, Loss1: 4.103440046e-02,loss2: 2.585700750e-01 Loss3: 3.401916750e+06,Time: 2.04\n",
      "It: 1260, Loss1: 2.269975655e-02,loss2: 6.710040569e-02 Loss3: 3.380235500e+06,Time: 1.98\n",
      "It: 1280, Loss1: 2.201168425e-02,loss2: 6.605014205e-02 Loss3: 3.358192750e+06,Time: 1.97\n",
      "It: 1300, Loss1: 2.138332091e-02,loss2: 1.677741855e-01 Loss3: 3.337028500e+06,Time: 2.01\n",
      "It: 1320, Loss1: 3.205863759e-02,loss2: 8.868812025e-02 Loss3: 3.316724500e+06,Time: 2.06\n",
      "It: 1340, Loss1: 2.173272520e-02,loss2: 8.168473840e-02 Loss3: 3.295472000e+06,Time: 2.00\n",
      "It: 1360, Loss1: 1.955612563e-02,loss2: 5.599363893e-02 Loss3: 3.274475500e+06,Time: 2.05\n",
      "It: 1380, Loss1: 2.689535171e-02,loss2: 1.133166105e-01 Loss3: 3.254279000e+06,Time: 2.03\n",
      "It: 1400, Loss1: 2.282992937e-02,loss2: 5.974213779e-02 Loss3: 3.235419250e+06,Time: 2.04\n",
      "It: 1420, Loss1: 1.934033073e-02,loss2: 5.198649690e-02 Loss3: 3.215651750e+06,Time: 2.00\n",
      "It: 1440, Loss1: 1.153701618e-01,loss2: 2.500877678e-01 Loss3: 3.196045000e+06,Time: 2.00\n",
      "It: 1460, Loss1: 1.660642028e-02,loss2: 5.540335923e-02 Loss3: 3.177795500e+06,Time: 2.03\n",
      "It: 1480, Loss1: 4.339471832e-02,loss2: 2.005437315e-01 Loss3: 3.158399750e+06,Time: 1.99\n",
      "It: 1500, Loss1: 1.146748587e-01,loss2: 4.554049969e-01 Loss3: 3.141468250e+06,Time: 2.01\n",
      "It: 1520, Loss1: 2.466055378e-02,loss2: 7.916775346e-02 Loss3: 3.123611250e+06,Time: 2.01\n",
      "It: 1540, Loss1: 1.263040584e-02,loss2: 3.058798239e-02 Loss3: 3.105870750e+06,Time: 2.03\n",
      "It: 1560, Loss1: 8.455710113e-02,loss2: 2.540874183e-01 Loss3: 3.088330500e+06,Time: 1.98\n",
      "It: 1580, Loss1: 4.006729648e-02,loss2: 1.129225343e-01 Loss3: 3.071220000e+06,Time: 2.06\n",
      "It: 1600, Loss1: 1.542123035e-02,loss2: 3.318464756e-02 Loss3: 3.052345750e+06,Time: 2.59\n",
      "It: 1620, Loss1: 2.757861316e-01,loss2: 8.668428659e-01 Loss3: 3.032370500e+06,Time: 2.20\n",
      "It: 1640, Loss1: 1.370853744e-02,loss2: 7.656966895e-02 Loss3: 3.016392250e+06,Time: 2.03\n",
      "It: 1660, Loss1: 1.166919805e-02,loss2: 3.185379133e-02 Loss3: 2.999346000e+06,Time: 1.96\n",
      "It: 1680, Loss1: 7.573350519e-02,loss2: 1.173127070e-01 Loss3: 2.982362750e+06,Time: 2.02\n",
      "It: 1700, Loss1: 3.779531643e-02,loss2: 7.830276340e-02 Loss3: 2.967605250e+06,Time: 2.00\n",
      "It: 1720, Loss1: 1.428492554e-02,loss2: 3.251842037e-02 Loss3: 2.952063500e+06,Time: 1.97\n",
      "It: 1740, Loss1: 1.245120727e-02,loss2: 2.743575349e-02 Loss3: 2.935799750e+06,Time: 1.98\n",
      "It: 1760, Loss1: 1.345094014e-02,loss2: 2.813704498e-02 Loss3: 2.919842750e+06,Time: 2.01\n",
      "It: 1780, Loss1: 6.373712420e-01,loss2: 1.098294735e+00 Loss3: 2.907897500e+06,Time: 1.99\n",
      "It: 1800, Loss1: 6.724667549e-02,loss2: 1.744605750e-01 Loss3: 2.893906250e+06,Time: 1.97\n",
      "It: 1820, Loss1: 1.693413965e-02,loss2: 3.505034745e-02 Loss3: 2.879743250e+06,Time: 1.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 1840, Loss1: 1.510326099e-02,loss2: 2.921966091e-02 Loss3: 2.865392500e+06,Time: 2.01\n",
      "It: 1860, Loss1: 1.352176536e-02,loss2: 2.643552236e-02 Loss3: 2.851351250e+06,Time: 2.02\n",
      "It: 1880, Loss1: 1.389726158e-02,loss2: 2.733360603e-02 Loss3: 2.837234000e+06,Time: 1.99\n",
      "It: 1900, Loss1: 1.167669669e-01,loss2: 8.870238066e-01 Loss3: 2.823138000e+06,Time: 1.97\n",
      "It: 1920, Loss1: 1.467443164e-02,loss2: 2.908515185e-02 Loss3: 2.810451250e+06,Time: 2.00\n",
      "It: 1940, Loss1: 1.524723694e-02,loss2: 4.105699062e-02 Loss3: 2.797011500e+06,Time: 2.06\n",
      "It: 1960, Loss1: 2.682698667e-01,loss2: 2.939397395e-01 Loss3: 2.784524000e+06,Time: 1.96\n",
      "It: 1980, Loss1: 1.826621443e-01,loss2: 3.122581542e-01 Loss3: 2.770753000e+06,Time: 2.57\n",
      "It: 20, Loss1: 1.426853687e-01,loss2: 6.703755260e-01 Loss3: 2.628293000e+06\n",
      "It: 40, Loss1: 1.951442212e-01,loss2: 1.049963474e+00 Loss3: 2.357544500e+06\n",
      "It: 60, Loss1: 2.340402156e-01,loss2: 1.005066633e+00 Loss3: 2.165930000e+06\n",
      "It: 80, Loss1: 4.018364549e-01,loss2: 1.191466808e+00 Loss3: 1.897699125e+06\n",
      "It: 100, Loss1: 3.851721287e-01,loss2: 1.339622736e+00 Loss3: 1.688957750e+06\n",
      "It: 120, Loss1: 3.526439965e-01,loss2: 1.147667408e+00 Loss3: 1.499818250e+06\n",
      "It: 140, Loss1: 9.920762479e-02,loss2: 1.015123606e+00 Loss3: 1.312131625e+06\n",
      "It: 160, Loss1: 1.264431626e-01,loss2: 6.008350849e-01 Loss3: 1.202761875e+06\n",
      "It: 180, Loss1: 2.293042243e-01,loss2: 5.752466917e-01 Loss3: 1.131886750e+06\n",
      "It: 200, Loss1: 1.666861176e-01,loss2: 1.025930405e+00 Loss3: 9.888199375e+05\n",
      "It: 220, Loss1: 2.092491686e-01,loss2: 1.021112323e+00 Loss3: 8.987813750e+05\n",
      "It: 240, Loss1: 1.317637861e-01,loss2: 8.710216284e-01 Loss3: 8.089460625e+05\n",
      "It: 260, Loss1: 1.246296689e-01,loss2: 7.020643950e-01 Loss3: 7.488712500e+05\n",
      "It: 280, Loss1: 5.664048344e-02,loss2: 7.028615475e-01 Loss3: 7.003274375e+05\n",
      "It: 300, Loss1: 7.740857452e-02,loss2: 7.512791157e-01 Loss3: 6.514590000e+05\n",
      "It: 320, Loss1: 5.695847794e-02,loss2: 5.235065818e-01 Loss3: 6.247513125e+05\n",
      "It: 340, Loss1: 9.105912596e-02,loss2: 4.510649741e-01 Loss3: 5.951988750e+05\n",
      "It: 360, Loss1: 1.087094620e-01,loss2: 4.920749962e-01 Loss3: 5.725001250e+05\n",
      "It: 380, Loss1: 1.089314744e-01,loss2: 4.189763665e-01 Loss3: 5.426078125e+05\n",
      "It: 400, Loss1: 7.250003517e-02,loss2: 4.353473783e-01 Loss3: 5.206136875e+05\n",
      "It: 420, Loss1: 5.902878940e-02,loss2: 4.504572153e-01 Loss3: 4.956325000e+05\n",
      "It: 440, Loss1: 5.844614655e-02,loss2: 4.056098461e-01 Loss3: 4.740564062e+05\n",
      "It: 460, Loss1: 5.352736637e-02,loss2: 4.086309373e-01 Loss3: 4.512624688e+05\n",
      "It: 480, Loss1: 6.621909887e-02,loss2: 4.784944355e-01 Loss3: 4.300361875e+05\n",
      "It: 500, Loss1: 4.924433306e-02,loss2: 4.449840784e-01 Loss3: 4.043902812e+05\n",
      "It: 520, Loss1: 5.098144710e-02,loss2: 4.215866923e-01 Loss3: 3.814973438e+05\n",
      "It: 540, Loss1: 5.281751603e-02,loss2: 4.214197397e-01 Loss3: 3.642793125e+05\n",
      "It: 560, Loss1: 1.093228906e-01,loss2: 6.255956888e-01 Loss3: 3.424821875e+05\n",
      "It: 580, Loss1: 4.489004612e-02,loss2: 4.869478941e-01 Loss3: 3.242005625e+05\n",
      "It: 600, Loss1: 7.748726010e-02,loss2: 4.966816306e-01 Loss3: 3.039589062e+05\n",
      "It: 620, Loss1: 6.887915730e-02,loss2: 5.903986692e-01 Loss3: 2.877605625e+05\n",
      "It: 640, Loss1: 8.650369197e-02,loss2: 5.547891259e-01 Loss3: 2.738858438e+05\n",
      "It: 660, Loss1: 7.132297754e-02,loss2: 6.672150493e-01 Loss3: 2.582523594e+05\n",
      "It: 680, Loss1: 1.050066873e-01,loss2: 5.895798206e-01 Loss3: 2.474800156e+05\n",
      "It: 700, Loss1: 9.067880362e-02,loss2: 6.531375051e-01 Loss3: 2.369517500e+05\n",
      "It: 720, Loss1: 1.193814352e-01,loss2: 5.329908729e-01 Loss3: 2.262931719e+05\n",
      "It: 740, Loss1: 1.159781516e-01,loss2: 5.690902472e-01 Loss3: 2.169302500e+05\n",
      "It: 760, Loss1: 1.135641485e-01,loss2: 5.737329721e-01 Loss3: 2.076679219e+05\n",
      "It: 780, Loss1: 1.213015020e-01,loss2: 5.948593616e-01 Loss3: 1.980170781e+05\n",
      "It: 800, Loss1: 1.361529231e-01,loss2: 5.444421768e-01 Loss3: 1.897840469e+05\n",
      "It: 820, Loss1: 8.049094677e-02,loss2: 5.839673281e-01 Loss3: 1.813181250e+05\n",
      "It: 840, Loss1: 5.069647357e-02,loss2: 4.507883787e-01 Loss3: 1.727747344e+05\n",
      "It: 860, Loss1: 4.525417089e-02,loss2: 3.795980215e-01 Loss3: 1.681239531e+05\n",
      "It: 880, Loss1: 3.818921000e-02,loss2: 3.803469241e-01 Loss3: 1.610741875e+05\n",
      "It: 900, Loss1: 2.511560172e-02,loss2: 4.214235544e-01 Loss3: 1.533011406e+05\n",
      "It: 920, Loss1: 6.402263790e-02,loss2: 4.884059429e-01 Loss3: 1.453659375e+05\n",
      "It: 940, Loss1: 9.818309546e-02,loss2: 4.531403780e-01 Loss3: 1.369918906e+05\n",
      "It: 960, Loss1: 5.529857799e-02,loss2: 3.548265100e-01 Loss3: 1.310648594e+05\n",
      "It: 980, Loss1: 5.573092028e-02,loss2: 3.696005046e-01 Loss3: 1.243560703e+05\n",
      "It: 1000, Loss1: 6.906910241e-02,loss2: 4.690989852e-01 Loss3: 1.170203281e+05\n",
      "It: 1020, Loss1: 9.976554662e-02,loss2: 4.530891180e-01 Loss3: 1.093314531e+05\n",
      "It: 1040, Loss1: 6.875343621e-02,loss2: 5.235530138e-01 Loss3: 1.027972422e+05\n",
      "It: 1060, Loss1: 6.068263203e-02,loss2: 5.629789233e-01 Loss3: 9.836674219e+04\n",
      "It: 1080, Loss1: 7.322647423e-02,loss2: 5.773043036e-01 Loss3: 9.523695312e+04\n",
      "It: 1100, Loss1: 6.578586251e-02,loss2: 5.611392856e-01 Loss3: 9.167438281e+04\n",
      "It: 1120, Loss1: 6.715860218e-02,loss2: 5.261286497e-01 Loss3: 8.821425781e+04\n",
      "It: 1140, Loss1: 9.982072562e-02,loss2: 5.068010688e-01 Loss3: 8.420847656e+04\n",
      "It: 1160, Loss1: 7.127268612e-02,loss2: 5.094255209e-01 Loss3: 8.106305469e+04\n",
      "It: 1180, Loss1: 8.041808754e-02,loss2: 5.107854605e-01 Loss3: 7.807755469e+04\n",
      "It: 1200, Loss1: 8.916705847e-02,loss2: 5.337053537e-01 Loss3: 7.482081250e+04\n",
      "It: 1220, Loss1: 9.529160708e-02,loss2: 5.792609453e-01 Loss3: 7.126596875e+04\n",
      "It: 1240, Loss1: 1.121734083e-01,loss2: 4.328329265e-01 Loss3: 6.884299219e+04\n",
      "It: 1260, Loss1: 9.168229997e-02,loss2: 4.316052198e-01 Loss3: 6.491776172e+04\n",
      "It: 1280, Loss1: 7.963652164e-02,loss2: 4.277697504e-01 Loss3: 6.247462891e+04\n",
      "It: 1300, Loss1: 9.909818321e-02,loss2: 4.468796551e-01 Loss3: 5.930151172e+04\n",
      "It: 1320, Loss1: 8.747405559e-02,loss2: 4.026940465e-01 Loss3: 5.596564453e+04\n",
      "It: 1340, Loss1: 4.767077044e-02,loss2: 3.395050168e-01 Loss3: 5.367749219e+04\n",
      "It: 1360, Loss1: 4.141848162e-02,loss2: 4.092265368e-01 Loss3: 5.124176172e+04\n",
      "It: 1380, Loss1: 5.226598307e-02,loss2: 3.552611470e-01 Loss3: 4.967895703e+04\n",
      "It: 1400, Loss1: 4.249176756e-02,loss2: 3.139167428e-01 Loss3: 4.774773438e+04\n",
      "It: 1420, Loss1: 5.245729908e-02,loss2: 3.480424285e-01 Loss3: 4.582553125e+04\n",
      "It: 1440, Loss1: 6.386820227e-02,loss2: 4.101442695e-01 Loss3: 4.411210156e+04\n",
      "It: 1460, Loss1: 8.041780442e-02,loss2: 4.140719175e-01 Loss3: 4.184410156e+04\n",
      "It: 1480, Loss1: 8.558151126e-02,loss2: 4.138086438e-01 Loss3: 4.011151172e+04\n",
      "It: 1500, Loss1: 7.258101553e-02,loss2: 3.863341212e-01 Loss3: 3.864635938e+04\n",
      "It: 1520, Loss1: 6.751821190e-02,loss2: 5.016330481e-01 Loss3: 3.658581250e+04\n",
      "It: 1540, Loss1: 5.179820210e-02,loss2: 5.061130524e-01 Loss3: 3.465947656e+04\n",
      "It: 1560, Loss1: 3.551094607e-02,loss2: 3.984170556e-01 Loss3: 3.325641016e+04\n",
      "It: 1580, Loss1: 3.232180327e-02,loss2: 3.530690670e-01 Loss3: 3.191773438e+04\n",
      "It: 1600, Loss1: 2.165005356e-02,loss2: 3.541248441e-01 Loss3: 3.045082812e+04\n",
      "It: 1620, Loss1: 3.869839385e-02,loss2: 4.432703257e-01 Loss3: 2.886019141e+04\n",
      "It: 1640, Loss1: 7.831757516e-02,loss2: 6.524230242e-01 Loss3: 2.782798438e+04\n",
      "It: 1660, Loss1: 5.365234241e-02,loss2: 5.675121546e-01 Loss3: 2.633886719e+04\n",
      "It: 1680, Loss1: 4.357333481e-02,loss2: 5.449393988e-01 Loss3: 2.505082227e+04\n",
      "It: 1700, Loss1: 3.856555372e-02,loss2: 5.528611541e-01 Loss3: 2.416089062e+04\n",
      "It: 1720, Loss1: 6.976280361e-02,loss2: 5.645385385e-01 Loss3: 2.315124805e+04\n",
      "It: 1740, Loss1: 5.230121687e-02,loss2: 5.917292833e-01 Loss3: 2.200567773e+04\n",
      "It: 1760, Loss1: 8.924418688e-02,loss2: 5.778537989e-01 Loss3: 2.056429688e+04\n",
      "It: 1780, Loss1: 7.925871760e-02,loss2: 5.587719679e-01 Loss3: 1.979537500e+04\n",
      "It: 1800, Loss1: 1.013584882e-01,loss2: 6.098603010e-01 Loss3: 1.852356055e+04\n",
      "It: 1820, Loss1: 7.798027992e-02,loss2: 6.309294105e-01 Loss3: 1.723095117e+04\n",
      "It: 1840, Loss1: 7.713627070e-02,loss2: 7.158218622e-01 Loss3: 1.576329883e+04\n",
      "It: 1860, Loss1: 9.967077523e-02,loss2: 7.887276411e-01 Loss3: 1.465534863e+04\n",
      "It: 1880, Loss1: 1.012708694e-01,loss2: 6.239390373e-01 Loss3: 1.358033887e+04\n",
      "It: 1900, Loss1: 1.187597513e-01,loss2: 5.735915899e-01 Loss3: 1.259323047e+04\n",
      "It: 1920, Loss1: 1.357651055e-01,loss2: 5.463770628e-01 Loss3: 1.204859961e+04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 1940, Loss1: 1.443550885e-01,loss2: 5.306302309e-01 Loss3: 1.145966602e+04\n",
      "It: 1960, Loss1: 1.352591515e-01,loss2: 5.099962950e-01 Loss3: 1.083078613e+04\n",
      "It: 1980, Loss1: 1.348793209e-01,loss2: 5.080296993e-01 Loss3: 1.025901074e+04\n",
      "It: 2000, Loss1: 1.360651106e-01,loss2: 5.183280110e-01 Loss3: 9.838369141e+03\n",
      "It: 2020, Loss1: 1.191903204e-01,loss2: 4.470966756e-01 Loss3: 9.446082031e+03\n",
      "It: 2040, Loss1: 1.194402426e-01,loss2: 4.804555178e-01 Loss3: 9.004183594e+03\n",
      "It: 2060, Loss1: 1.398692727e-01,loss2: 4.592418969e-01 Loss3: 8.711050781e+03\n",
      "It: 2080, Loss1: 1.370035410e-01,loss2: 4.014828205e-01 Loss3: 8.385174805e+03\n",
      "It: 2100, Loss1: 1.205293238e-01,loss2: 4.391017556e-01 Loss3: 7.892111816e+03\n",
      "It: 2120, Loss1: 9.048919380e-02,loss2: 4.217693806e-01 Loss3: 7.394165039e+03\n",
      "It: 2140, Loss1: 7.879944146e-02,loss2: 3.985630274e-01 Loss3: 7.029258301e+03\n",
      "It: 2160, Loss1: 8.087045699e-02,loss2: 3.683637381e-01 Loss3: 6.733919434e+03\n",
      "It: 2180, Loss1: 7.087714225e-02,loss2: 3.898351789e-01 Loss3: 6.458791504e+03\n",
      "It: 2200, Loss1: 6.820324808e-02,loss2: 3.846062124e-01 Loss3: 6.265856934e+03\n",
      "It: 2220, Loss1: 7.312529534e-02,loss2: 4.052862525e-01 Loss3: 6.019060547e+03\n",
      "It: 2240, Loss1: 6.231561676e-02,loss2: 4.434661269e-01 Loss3: 5.736202637e+03\n",
      "It: 2260, Loss1: 4.935029522e-02,loss2: 4.472721815e-01 Loss3: 5.431487793e+03\n",
      "It: 2280, Loss1: 4.609454423e-02,loss2: 4.546355605e-01 Loss3: 5.190206543e+03\n",
      "It: 2300, Loss1: 4.106945544e-02,loss2: 4.325034618e-01 Loss3: 5.009050293e+03\n",
      "It: 2320, Loss1: 3.671770170e-02,loss2: 4.419332743e-01 Loss3: 4.764033203e+03\n",
      "It: 2340, Loss1: 2.631060220e-02,loss2: 4.665285349e-01 Loss3: 4.541850098e+03\n",
      "It: 2360, Loss1: 2.560631558e-02,loss2: 4.255898297e-01 Loss3: 4.405093750e+03\n",
      "It: 2380, Loss1: 3.226576373e-02,loss2: 4.312648773e-01 Loss3: 4.110844238e+03\n",
      "It: 2400, Loss1: 1.853558607e-02,loss2: 3.871285319e-01 Loss3: 3.999306396e+03\n",
      "It: 2420, Loss1: 1.805600710e-02,loss2: 4.533340931e-01 Loss3: 3.758652832e+03\n",
      "It: 2440, Loss1: 1.355261169e-02,loss2: 4.769988656e-01 Loss3: 3.574600098e+03\n",
      "It: 2460, Loss1: 1.084962394e-02,loss2: 4.366893768e-01 Loss3: 3.390765625e+03\n",
      "It: 2480, Loss1: 1.668113284e-02,loss2: 3.688693047e-01 Loss3: 3.310759521e+03\n",
      "It: 2500, Loss1: 9.960018098e-03,loss2: 4.018074274e-01 Loss3: 3.133250000e+03\n",
      "It: 2520, Loss1: 1.058031712e-02,loss2: 3.745623231e-01 Loss3: 2.994254395e+03\n",
      "It: 2540, Loss1: 1.201967895e-02,loss2: 4.152559638e-01 Loss3: 2.849974121e+03\n",
      "It: 2560, Loss1: 1.894055493e-02,loss2: 4.133374393e-01 Loss3: 2.702984375e+03\n",
      "It: 2580, Loss1: 1.795035042e-02,loss2: 3.574299216e-01 Loss3: 2.592775146e+03\n",
      "It: 2600, Loss1: 2.162445709e-02,loss2: 3.167060018e-01 Loss3: 2.503467529e+03\n",
      "It: 2620, Loss1: 2.385882474e-02,loss2: 3.270282149e-01 Loss3: 2.382033691e+03\n",
      "It: 2640, Loss1: 2.154051140e-02,loss2: 3.552476466e-01 Loss3: 2.273692627e+03\n",
      "It: 2660, Loss1: 1.282927487e-02,loss2: 3.515040874e-01 Loss3: 2.181466064e+03\n",
      "It: 2680, Loss1: 1.206529140e-02,loss2: 3.380865753e-01 Loss3: 2.064938965e+03\n",
      "It: 2700, Loss1: 2.248643152e-02,loss2: 3.218683898e-01 Loss3: 1.958097168e+03\n",
      "It: 2720, Loss1: 1.342445984e-02,loss2: 3.015936613e-01 Loss3: 1.861663208e+03\n",
      "It: 2740, Loss1: 1.508333720e-02,loss2: 3.212069273e-01 Loss3: 1.769000610e+03\n",
      "It: 2760, Loss1: 1.455328427e-02,loss2: 3.535155058e-01 Loss3: 1.681473389e+03\n",
      "It: 2780, Loss1: 1.816874556e-02,loss2: 3.091993928e-01 Loss3: 1.546782837e+03\n",
      "It: 2800, Loss1: 2.353021875e-02,loss2: 2.927325368e-01 Loss3: 1.481868896e+03\n",
      "It: 2820, Loss1: 1.857915148e-02,loss2: 3.027131855e-01 Loss3: 1.410586792e+03\n",
      "It: 2840, Loss1: 2.846783586e-02,loss2: 2.812848687e-01 Loss3: 1.325788574e+03\n",
      "It: 2860, Loss1: 2.468769997e-02,loss2: 2.678258121e-01 Loss3: 1.271216431e+03\n",
      "It: 2880, Loss1: 2.406162396e-02,loss2: 2.656336129e-01 Loss3: 1.230703247e+03\n",
      "It: 2900, Loss1: 2.386672981e-02,loss2: 2.906669974e-01 Loss3: 1.163645874e+03\n",
      "It: 2920, Loss1: 2.124522440e-02,loss2: 2.886897922e-01 Loss3: 1.132652710e+03\n",
      "It: 2940, Loss1: 2.982855216e-02,loss2: 2.756392658e-01 Loss3: 1.093693970e+03\n",
      "It: 2960, Loss1: 2.033220232e-02,loss2: 2.693427503e-01 Loss3: 1.048889771e+03\n",
      "It: 2980, Loss1: 1.788697764e-02,loss2: 2.532574832e-01 Loss3: 1.025974976e+03\n",
      "It: 3000, Loss1: 1.242978871e-02,loss2: 2.510571182e-01 Loss3: 9.871406250e+02\n",
      "It: 3020, Loss1: 1.110545825e-02,loss2: 2.362066507e-01 Loss3: 9.412171021e+02\n",
      "It: 3040, Loss1: 1.071783993e-02,loss2: 2.513171434e-01 Loss3: 9.011232910e+02\n",
      "It: 3060, Loss1: 1.081738435e-02,loss2: 2.507212162e-01 Loss3: 8.462188110e+02\n",
      "It: 3080, Loss1: 2.090994082e-02,loss2: 2.635388374e-01 Loss3: 8.018074951e+02\n",
      "It: 3100, Loss1: 1.639180072e-02,loss2: 2.496298850e-01 Loss3: 7.852197266e+02\n",
      "It: 3120, Loss1: 8.060229942e-03,loss2: 2.491933703e-01 Loss3: 7.580291138e+02\n",
      "It: 3140, Loss1: 8.201253600e-03,loss2: 2.628804445e-01 Loss3: 7.305365601e+02\n",
      "It: 3160, Loss1: 9.961152449e-03,loss2: 2.451303601e-01 Loss3: 7.115490723e+02\n",
      "It: 3180, Loss1: 6.370239425e-03,loss2: 2.271298468e-01 Loss3: 6.870825806e+02\n",
      "It: 3200, Loss1: 7.455585990e-03,loss2: 2.147239745e-01 Loss3: 6.649973145e+02\n",
      "It: 3220, Loss1: 9.278299287e-03,loss2: 2.067676485e-01 Loss3: 6.543588867e+02\n",
      "It: 3240, Loss1: 6.141969468e-03,loss2: 1.946044862e-01 Loss3: 6.339529419e+02\n",
      "It: 3260, Loss1: 7.837398909e-03,loss2: 1.969558299e-01 Loss3: 6.070364380e+02\n",
      "It: 3280, Loss1: 1.085022185e-02,loss2: 2.121360004e-01 Loss3: 5.938517456e+02\n",
      "It: 3300, Loss1: 9.545323439e-03,loss2: 2.042269111e-01 Loss3: 5.784179077e+02\n",
      "It: 3320, Loss1: 1.209429093e-02,loss2: 2.080345750e-01 Loss3: 5.597760010e+02\n",
      "It: 3340, Loss1: 1.275917236e-02,loss2: 1.994865984e-01 Loss3: 5.384299927e+02\n",
      "It: 3360, Loss1: 8.330100216e-03,loss2: 1.852812767e-01 Loss3: 5.239415283e+02\n",
      "It: 3380, Loss1: 7.083973847e-03,loss2: 1.823862791e-01 Loss3: 5.132094727e+02\n",
      "It: 3400, Loss1: 6.857835222e-03,loss2: 1.772949994e-01 Loss3: 4.974703064e+02\n",
      "It: 3420, Loss1: 7.288052235e-03,loss2: 1.593542099e-01 Loss3: 4.831639099e+02\n",
      "It: 3440, Loss1: 8.642495610e-03,loss2: 1.508097798e-01 Loss3: 4.735354919e+02\n",
      "It: 3460, Loss1: 8.482929319e-03,loss2: 1.440095007e-01 Loss3: 4.647087097e+02\n",
      "It: 3480, Loss1: 9.054683149e-03,loss2: 1.581776738e-01 Loss3: 4.482228088e+02\n",
      "It: 3500, Loss1: 1.198367309e-02,loss2: 1.526121199e-01 Loss3: 4.349672546e+02\n",
      "It: 3520, Loss1: 1.522904355e-02,loss2: 1.495589763e-01 Loss3: 4.224216919e+02\n",
      "It: 3540, Loss1: 1.482071541e-02,loss2: 1.439960897e-01 Loss3: 4.126904907e+02\n",
      "It: 3560, Loss1: 1.270763576e-02,loss2: 1.634289771e-01 Loss3: 4.055038452e+02\n",
      "It: 3580, Loss1: 1.498175599e-02,loss2: 1.346161962e-01 Loss3: 3.974819641e+02\n",
      "It: 3600, Loss1: 2.148285322e-02,loss2: 1.293897331e-01 Loss3: 3.874767151e+02\n",
      "It: 3620, Loss1: 1.886572875e-02,loss2: 1.237575188e-01 Loss3: 3.785223083e+02\n",
      "It: 3640, Loss1: 1.771697402e-02,loss2: 1.182985008e-01 Loss3: 3.666381226e+02\n",
      "It: 3660, Loss1: 1.800592989e-02,loss2: 1.057638749e-01 Loss3: 3.534758301e+02\n",
      "It: 3680, Loss1: 1.288190205e-02,loss2: 1.136492342e-01 Loss3: 3.432520142e+02\n",
      "It: 3700, Loss1: 1.237046532e-02,loss2: 1.100312248e-01 Loss3: 3.334798584e+02\n",
      "It: 3720, Loss1: 1.092811860e-02,loss2: 1.054550186e-01 Loss3: 3.265976562e+02\n",
      "It: 3740, Loss1: 8.872571401e-03,loss2: 1.087097526e-01 Loss3: 3.185455627e+02\n",
      "It: 3760, Loss1: 1.400975883e-02,loss2: 1.042278036e-01 Loss3: 3.120841980e+02\n",
      "It: 3780, Loss1: 6.588307209e-03,loss2: 1.127791703e-01 Loss3: 3.010509644e+02\n",
      "It: 3800, Loss1: 5.184308626e-03,loss2: 1.071754396e-01 Loss3: 2.932792358e+02\n",
      "It: 3820, Loss1: 5.347413011e-03,loss2: 1.093839854e-01 Loss3: 2.831869812e+02\n",
      "It: 3840, Loss1: 4.534813575e-03,loss2: 1.073306054e-01 Loss3: 2.720528870e+02\n",
      "It: 3860, Loss1: 4.060470033e-03,loss2: 1.031374186e-01 Loss3: 2.656763000e+02\n",
      "It: 3880, Loss1: 3.037375165e-03,loss2: 9.970945120e-02 Loss3: 2.575414124e+02\n",
      "It: 3900, Loss1: 5.218066275e-03,loss2: 9.994381666e-02 Loss3: 2.499369202e+02\n",
      "It: 3920, Loss1: 4.262836650e-03,loss2: 1.032042950e-01 Loss3: 2.438229523e+02\n",
      "It: 3940, Loss1: 2.516803099e-03,loss2: 9.577152133e-02 Loss3: 2.387334442e+02\n",
      "It: 3960, Loss1: 3.794029588e-03,loss2: 1.071435660e-01 Loss3: 2.306210480e+02\n",
      "It: 3980, Loss1: 5.679242779e-03,loss2: 1.142134368e-01 Loss3: 2.240171967e+02\n",
      "It: 4000, Loss1: 5.466039758e-03,loss2: 1.169115752e-01 Loss3: 2.178023224e+02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 4020, Loss1: 6.652958691e-03,loss2: 1.152143031e-01 Loss3: 2.141481934e+02\n",
      "It: 4040, Loss1: 7.024302613e-03,loss2: 1.167160869e-01 Loss3: 2.098681488e+02\n",
      "It: 4060, Loss1: 5.859207828e-03,loss2: 1.156165451e-01 Loss3: 2.058452606e+02\n",
      "It: 4080, Loss1: 5.378402770e-03,loss2: 1.129207313e-01 Loss3: 1.992968750e+02\n",
      "It: 4100, Loss1: 6.794097368e-03,loss2: 1.076138020e-01 Loss3: 1.937928925e+02\n",
      "It: 4120, Loss1: 4.593182821e-03,loss2: 1.076089665e-01 Loss3: 1.910915680e+02\n",
      "It: 4140, Loss1: 5.875727162e-03,loss2: 9.373544157e-02 Loss3: 1.874279175e+02\n",
      "It: 4160, Loss1: 6.386055611e-03,loss2: 1.038007438e-01 Loss3: 1.830833435e+02\n",
      "It: 4180, Loss1: 4.999569152e-03,loss2: 1.033883691e-01 Loss3: 1.783876190e+02\n",
      "It: 4200, Loss1: 5.837442353e-03,loss2: 9.181916714e-02 Loss3: 1.742249756e+02\n",
      "It: 4220, Loss1: 6.072137970e-03,loss2: 8.952699602e-02 Loss3: 1.707171783e+02\n",
      "It: 4240, Loss1: 6.051336415e-03,loss2: 9.249347448e-02 Loss3: 1.660517120e+02\n",
      "It: 4260, Loss1: 4.353642464e-03,loss2: 9.790691733e-02 Loss3: 1.606312561e+02\n",
      "It: 4280, Loss1: 4.465006292e-03,loss2: 9.739544243e-02 Loss3: 1.588682251e+02\n",
      "It: 4300, Loss1: 2.894938691e-03,loss2: 1.024470329e-01 Loss3: 1.544564209e+02\n",
      "It: 4320, Loss1: 2.990822075e-03,loss2: 9.991684556e-02 Loss3: 1.514882812e+02\n",
      "It: 4340, Loss1: 2.739086514e-03,loss2: 9.809543192e-02 Loss3: 1.493438721e+02\n",
      "It: 4360, Loss1: 2.516333945e-03,loss2: 9.345918149e-02 Loss3: 1.466378021e+02\n",
      "It: 4380, Loss1: 2.652096795e-03,loss2: 8.965300024e-02 Loss3: 1.437396698e+02\n",
      "It: 4400, Loss1: 3.496482270e-03,loss2: 9.198696166e-02 Loss3: 1.406136322e+02\n",
      "It: 4420, Loss1: 3.013056936e-03,loss2: 9.743799269e-02 Loss3: 1.365947571e+02\n",
      "It: 4440, Loss1: 4.448415712e-03,loss2: 9.525187314e-02 Loss3: 1.337349548e+02\n",
      "It: 4460, Loss1: 3.369329032e-03,loss2: 1.019970402e-01 Loss3: 1.307129517e+02\n",
      "It: 4480, Loss1: 4.087190609e-03,loss2: 9.814199805e-02 Loss3: 1.278639755e+02\n",
      "It: 4500, Loss1: 5.022874102e-03,loss2: 8.986216784e-02 Loss3: 1.257902756e+02\n",
      "It: 4520, Loss1: 6.737433840e-03,loss2: 8.834058046e-02 Loss3: 1.238039780e+02\n",
      "It: 4540, Loss1: 7.455790881e-03,loss2: 8.723397553e-02 Loss3: 1.217310486e+02\n",
      "It: 4560, Loss1: 6.848596036e-03,loss2: 7.931853086e-02 Loss3: 1.194016266e+02\n",
      "It: 4580, Loss1: 7.356523536e-03,loss2: 7.413575798e-02 Loss3: 1.179682770e+02\n",
      "It: 4600, Loss1: 6.020647008e-03,loss2: 7.369544357e-02 Loss3: 1.159866486e+02\n",
      "It: 4620, Loss1: 3.998559900e-03,loss2: 7.025712729e-02 Loss3: 1.141934967e+02\n",
      "It: 4640, Loss1: 4.936020356e-03,loss2: 7.320495695e-02 Loss3: 1.122718735e+02\n",
      "It: 4660, Loss1: 4.533378407e-03,loss2: 7.267540693e-02 Loss3: 1.106425781e+02\n",
      "It: 4680, Loss1: 4.133766051e-03,loss2: 7.477271557e-02 Loss3: 1.088581772e+02\n",
      "It: 4700, Loss1: 3.075247630e-03,loss2: 7.364574820e-02 Loss3: 1.077272110e+02\n",
      "It: 4720, Loss1: 3.818049794e-03,loss2: 7.919038832e-02 Loss3: 1.053319397e+02\n",
      "It: 4740, Loss1: 5.049809348e-03,loss2: 8.026344329e-02 Loss3: 1.032279434e+02\n",
      "It: 4760, Loss1: 5.060007796e-03,loss2: 7.814189792e-02 Loss3: 1.021183014e+02\n",
      "It: 4780, Loss1: 6.464393344e-03,loss2: 7.578556985e-02 Loss3: 1.008012619e+02\n",
      "It: 4800, Loss1: 6.563401781e-03,loss2: 8.029417694e-02 Loss3: 9.904605103e+01\n",
      "It: 4820, Loss1: 5.600034259e-03,loss2: 7.740181684e-02 Loss3: 9.749144745e+01\n",
      "It: 4840, Loss1: 5.818966310e-03,loss2: 7.941793650e-02 Loss3: 9.584470367e+01\n",
      "It: 4860, Loss1: 6.298817229e-03,loss2: 7.798378170e-02 Loss3: 9.442613983e+01\n",
      "It: 4880, Loss1: 5.379678216e-03,loss2: 7.687970251e-02 Loss3: 9.215541077e+01\n",
      "It: 4900, Loss1: 4.567847122e-03,loss2: 7.311622798e-02 Loss3: 9.072094727e+01\n",
      "It: 4920, Loss1: 4.904452711e-03,loss2: 7.502970099e-02 Loss3: 8.921733856e+01\n",
      "It: 4940, Loss1: 3.499280894e-03,loss2: 7.947370410e-02 Loss3: 8.714136505e+01\n",
      "It: 4960, Loss1: 3.395445412e-03,loss2: 1.005343646e-01 Loss3: 8.658384705e+01\n",
      "It: 4980, Loss1: 2.498865826e-03,loss2: 7.324002683e-02 Loss3: 8.407245636e+01\n",
      "It: 5000, Loss1: 2.791573992e-03,loss2: 7.473140955e-02 Loss3: 8.232797241e+01\n",
      "It: 5020, Loss1: 5.320360884e-03,loss2: 7.682199031e-02 Loss3: 8.030902863e+01\n",
      "It: 5040, Loss1: 4.110286478e-03,loss2: 7.710506022e-02 Loss3: 7.890152740e+01\n",
      "It: 5060, Loss1: 1.793360920e-03,loss2: 7.715074718e-02 Loss3: 7.727209473e+01\n",
      "It: 5080, Loss1: 1.439691288e-03,loss2: 7.900828868e-02 Loss3: 7.691432190e+01\n",
      "It: 5100, Loss1: 9.942428442e-04,loss2: 7.233279943e-02 Loss3: 7.543833923e+01\n",
      "It: 5120, Loss1: 1.248854795e-03,loss2: 7.082967460e-02 Loss3: 7.396865082e+01\n",
      "It: 5140, Loss1: 1.548345666e-03,loss2: 7.080748677e-02 Loss3: 7.223862457e+01\n",
      "It: 5160, Loss1: 3.244512016e-03,loss2: 6.954105198e-02 Loss3: 7.107728577e+01\n",
      "It: 5180, Loss1: 3.519106656e-03,loss2: 6.860867143e-02 Loss3: 6.972744751e+01\n",
      "It: 5200, Loss1: 2.980158664e-03,loss2: 7.069489360e-02 Loss3: 6.835523987e+01\n",
      "It: 5220, Loss1: 2.225033939e-03,loss2: 6.819281727e-02 Loss3: 6.719525146e+01\n",
      "It: 5240, Loss1: 4.004087765e-03,loss2: 7.120661438e-02 Loss3: 6.595643616e+01\n",
      "It: 5260, Loss1: 3.271703376e-03,loss2: 6.959402561e-02 Loss3: 6.481784821e+01\n",
      "It: 5280, Loss1: 7.457136177e-03,loss2: 6.931559741e-02 Loss3: 6.316968918e+01\n",
      "It: 5300, Loss1: 3.696136875e-03,loss2: 7.424215972e-02 Loss3: 6.163859940e+01\n",
      "It: 5320, Loss1: 2.473605331e-03,loss2: 7.331878692e-02 Loss3: 6.056706238e+01\n",
      "It: 5340, Loss1: 2.235944383e-03,loss2: 7.738527656e-02 Loss3: 5.928866959e+01\n",
      "It: 5360, Loss1: 1.198842539e-03,loss2: 8.491657674e-02 Loss3: 5.791419983e+01\n",
      "It: 5380, Loss1: 2.199050272e-03,loss2: 8.459196240e-02 Loss3: 5.666921234e+01\n",
      "It: 5400, Loss1: 3.882036312e-03,loss2: 8.382363617e-02 Loss3: 5.551653671e+01\n",
      "It: 5420, Loss1: 3.899044124e-03,loss2: 8.856049925e-02 Loss3: 5.432931900e+01\n",
      "It: 5440, Loss1: 3.469054587e-03,loss2: 8.122517169e-02 Loss3: 5.308192444e+01\n",
      "It: 5460, Loss1: 2.353594638e-03,loss2: 8.225560188e-02 Loss3: 5.205028915e+01\n",
      "It: 5480, Loss1: 3.671379993e-03,loss2: 8.263160288e-02 Loss3: 5.075911331e+01\n",
      "It: 5500, Loss1: 4.001947120e-03,loss2: 8.211500943e-02 Loss3: 4.973624802e+01\n",
      "It: 5520, Loss1: 3.160576569e-03,loss2: 8.188494295e-02 Loss3: 4.869176102e+01\n",
      "It: 5540, Loss1: 3.499678802e-03,loss2: 7.960865647e-02 Loss3: 4.787202454e+01\n",
      "It: 5560, Loss1: 4.314522725e-03,loss2: 7.796959579e-02 Loss3: 4.711184311e+01\n",
      "It: 5580, Loss1: 3.609055653e-03,loss2: 8.105326444e-02 Loss3: 4.623044968e+01\n",
      "It: 5600, Loss1: 3.224724205e-03,loss2: 8.070022613e-02 Loss3: 4.550902939e+01\n",
      "It: 5620, Loss1: 4.031388555e-03,loss2: 8.068754524e-02 Loss3: 4.429619980e+01\n",
      "It: 5640, Loss1: 4.001497291e-03,loss2: 7.574556023e-02 Loss3: 4.358356857e+01\n",
      "It: 5660, Loss1: 4.066541791e-03,loss2: 7.706902176e-02 Loss3: 4.259624863e+01\n",
      "It: 5680, Loss1: 4.295762628e-03,loss2: 7.160900533e-02 Loss3: 4.209663773e+01\n",
      "It: 5700, Loss1: 3.395101987e-03,loss2: 7.084909081e-02 Loss3: 4.152425003e+01\n",
      "It: 5720, Loss1: 3.629510291e-03,loss2: 6.905682385e-02 Loss3: 4.090979004e+01\n",
      "It: 5740, Loss1: 3.234438365e-03,loss2: 6.789002568e-02 Loss3: 4.022384644e+01\n",
      "It: 5760, Loss1: 3.759802086e-03,loss2: 6.659093499e-02 Loss3: 3.958736038e+01\n",
      "It: 5780, Loss1: 4.052566364e-03,loss2: 6.652539968e-02 Loss3: 3.888181686e+01\n",
      "It: 5800, Loss1: 3.778413171e-03,loss2: 6.556612998e-02 Loss3: 3.847479248e+01\n",
      "It: 5820, Loss1: 4.006532952e-03,loss2: 6.422867626e-02 Loss3: 3.815368652e+01\n",
      "It: 5840, Loss1: 4.436647985e-03,loss2: 6.492589414e-02 Loss3: 3.772304153e+01\n",
      "It: 5860, Loss1: 4.868536722e-03,loss2: 8.309967816e-02 Loss3: 3.768222427e+01\n",
      "It: 5880, Loss1: 3.892426379e-03,loss2: 6.880532205e-02 Loss3: 3.669137573e+01\n",
      "It: 5900, Loss1: 3.685774049e-03,loss2: 6.762558967e-02 Loss3: 3.610018921e+01\n",
      "It: 5920, Loss1: 4.746707622e-03,loss2: 6.622721255e-02 Loss3: 3.555694199e+01\n",
      "It: 5940, Loss1: 4.030930810e-03,loss2: 6.792248785e-02 Loss3: 3.489688873e+01\n",
      "It: 5960, Loss1: 4.709446337e-03,loss2: 6.774514914e-02 Loss3: 3.431805038e+01\n",
      "It: 5980, Loss1: 5.353756715e-03,loss2: 6.772913039e-02 Loss3: 3.387149429e+01\n",
      "It: 6000, Loss1: 4.982577171e-03,loss2: 6.959192455e-02 Loss3: 3.344159317e+01\n",
      "It: 6020, Loss1: 4.447776824e-03,loss2: 7.463417947e-02 Loss3: 3.289175415e+01\n",
      "It: 6040, Loss1: 4.146449734e-03,loss2: 7.493112981e-02 Loss3: 3.274015045e+01\n",
      "It: 6060, Loss1: 4.882664885e-03,loss2: 7.212918997e-02 Loss3: 3.205691147e+01\n",
      "It: 6080, Loss1: 5.718983244e-03,loss2: 7.212804258e-02 Loss3: 3.169808769e+01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 6100, Loss1: 6.458535790e-03,loss2: 7.114468515e-02 Loss3: 3.138187408e+01\n",
      "It: 6120, Loss1: 7.274859119e-03,loss2: 7.074565440e-02 Loss3: 3.102278709e+01\n",
      "It: 6140, Loss1: 7.041461300e-03,loss2: 6.987555325e-02 Loss3: 3.060930634e+01\n",
      "It: 6160, Loss1: 7.038749289e-03,loss2: 6.993846595e-02 Loss3: 3.035240364e+01\n",
      "It: 6180, Loss1: 7.673378568e-03,loss2: 6.960262358e-02 Loss3: 2.999162483e+01\n",
      "It: 6200, Loss1: 8.968073875e-03,loss2: 6.702522933e-02 Loss3: 2.957426262e+01\n",
      "It: 6220, Loss1: 8.637378924e-03,loss2: 6.692488492e-02 Loss3: 2.931177521e+01\n",
      "It: 6240, Loss1: 8.637239225e-03,loss2: 6.557294726e-02 Loss3: 2.904891014e+01\n",
      "It: 6260, Loss1: 8.539195172e-03,loss2: 6.435775012e-02 Loss3: 2.879022217e+01\n",
      "It: 6280, Loss1: 8.918364532e-03,loss2: 6.413435191e-02 Loss3: 2.849548721e+01\n",
      "It: 6300, Loss1: 7.933348417e-03,loss2: 6.100641936e-02 Loss3: 2.825849724e+01\n",
      "It: 6320, Loss1: 7.788036484e-03,loss2: 5.922152847e-02 Loss3: 2.797328758e+01\n",
      "It: 6340, Loss1: 8.676742204e-03,loss2: 5.933503434e-02 Loss3: 2.758385277e+01\n",
      "It: 6360, Loss1: 8.316067979e-03,loss2: 5.878911912e-02 Loss3: 2.730550385e+01\n",
      "It: 6380, Loss1: 7.646068931e-03,loss2: 5.699846148e-02 Loss3: 2.710758781e+01\n",
      "It: 6400, Loss1: 6.998435594e-03,loss2: 5.715577304e-02 Loss3: 2.670314598e+01\n",
      "It: 6420, Loss1: 6.808821578e-03,loss2: 5.613367260e-02 Loss3: 2.643448067e+01\n",
      "It: 6440, Loss1: 6.773765665e-03,loss2: 5.602750182e-02 Loss3: 2.623164940e+01\n",
      "It: 6460, Loss1: 6.251562387e-03,loss2: 5.655180663e-02 Loss3: 2.600376892e+01\n",
      "It: 6480, Loss1: 5.138779059e-03,loss2: 5.625906587e-02 Loss3: 2.568534660e+01\n",
      "It: 6500, Loss1: 5.342599470e-03,loss2: 5.648965016e-02 Loss3: 2.560370636e+01\n",
      "It: 6520, Loss1: 5.335530732e-03,loss2: 5.648133159e-02 Loss3: 2.560334587e+01\n",
      "It: 6540, Loss1: 5.335530732e-03,loss2: 5.648133159e-02 Loss3: 2.560334587e+01\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 3.009171\n",
      "  Number of iterations: 5958\n",
      "  Number of functions evaluations: 6546\n",
      "It: 20, Loss1: 5.333270878e-03,loss2: 5.769951642e-02 Loss3: 2.557398605e+01\n",
      "It: 40, Loss1: 5.187672097e-03,loss2: 5.877602845e-02 Loss3: 2.539087486e+01\n",
      "It: 60, Loss1: 5.231253803e-03,loss2: 5.985124409e-02 Loss3: 2.510916519e+01\n",
      "It: 80, Loss1: 5.059638061e-03,loss2: 6.189620495e-02 Loss3: 2.484115219e+01\n",
      "It: 100, Loss1: 5.399257876e-03,loss2: 6.600475311e-02 Loss3: 2.455583191e+01\n",
      "It: 120, Loss1: 4.517988302e-03,loss2: 6.585751474e-02 Loss3: 2.419324112e+01\n",
      "It: 140, Loss1: 4.499143921e-03,loss2: 6.751735508e-02 Loss3: 2.403292274e+01\n",
      "It: 160, Loss1: 6.409505382e-03,loss2: 7.116445154e-02 Loss3: 2.376178741e+01\n",
      "It: 180, Loss1: 4.853380378e-03,loss2: 7.187145948e-02 Loss3: 2.344990730e+01\n",
      "It: 200, Loss1: 5.082238000e-03,loss2: 7.557204366e-02 Loss3: 2.324829674e+01\n",
      "It: 220, Loss1: 5.177392159e-03,loss2: 7.410964370e-02 Loss3: 2.305526924e+01\n",
      "It: 240, Loss1: 4.409899469e-03,loss2: 7.488536090e-02 Loss3: 2.288124657e+01\n",
      "It: 260, Loss1: 4.093749449e-03,loss2: 7.373540848e-02 Loss3: 2.277136230e+01\n",
      "It: 280, Loss1: 5.061377771e-03,loss2: 7.357533276e-02 Loss3: 2.260305977e+01\n",
      "It: 300, Loss1: 5.462046247e-03,loss2: 7.367065549e-02 Loss3: 2.244078064e+01\n",
      "It: 320, Loss1: 3.987424541e-03,loss2: 6.815987080e-02 Loss3: 2.233590317e+01\n",
      "It: 340, Loss1: 3.309927881e-03,loss2: 6.872817129e-02 Loss3: 2.220866394e+01\n",
      "It: 360, Loss1: 3.519202583e-03,loss2: 6.904236972e-02 Loss3: 2.207489777e+01\n",
      "It: 380, Loss1: 3.730230266e-03,loss2: 6.861486286e-02 Loss3: 2.194515228e+01\n",
      "It: 400, Loss1: 3.720704233e-03,loss2: 6.879039854e-02 Loss3: 2.179290390e+01\n",
      "It: 420, Loss1: 3.535008524e-03,loss2: 6.688138843e-02 Loss3: 2.170767784e+01\n",
      "It: 440, Loss1: 3.249302506e-03,loss2: 6.654846668e-02 Loss3: 2.161344719e+01\n",
      "It: 460, Loss1: 3.349649487e-03,loss2: 6.836286187e-02 Loss3: 2.144663048e+01\n",
      "It: 480, Loss1: 2.925037174e-03,loss2: 6.887603551e-02 Loss3: 2.127925873e+01\n",
      "It: 500, Loss1: 3.480599029e-03,loss2: 6.916546822e-02 Loss3: 2.114395332e+01\n",
      "It: 520, Loss1: 3.772302531e-03,loss2: 7.120914757e-02 Loss3: 2.097016716e+01\n",
      "It: 540, Loss1: 4.017378204e-03,loss2: 7.240170240e-02 Loss3: 2.087922287e+01\n",
      "It: 560, Loss1: 3.216936253e-03,loss2: 7.353797555e-02 Loss3: 2.076427269e+01\n",
      "It: 580, Loss1: 2.852947218e-03,loss2: 7.663615793e-02 Loss3: 2.060746956e+01\n",
      "It: 600, Loss1: 2.363782376e-03,loss2: 7.606267184e-02 Loss3: 2.052946854e+01\n",
      "It: 620, Loss1: 2.889370546e-03,loss2: 7.858791202e-02 Loss3: 2.035347366e+01\n",
      "It: 640, Loss1: 3.420983441e-03,loss2: 8.153695613e-02 Loss3: 2.021599007e+01\n",
      "It: 660, Loss1: 3.733841237e-03,loss2: 8.068859577e-02 Loss3: 2.005472565e+01\n",
      "It: 680, Loss1: 3.952273633e-03,loss2: 8.052130044e-02 Loss3: 1.995598412e+01\n",
      "It: 700, Loss1: 4.243210424e-03,loss2: 8.204347640e-02 Loss3: 1.982621574e+01\n",
      "It: 720, Loss1: 4.243211355e-03,loss2: 8.204348385e-02 Loss3: 1.982621384e+01\n",
      "It: 740, Loss1: 4.413983319e-03,loss2: 8.297566324e-02 Loss3: 1.976499939e+01\n",
      "It: 760, Loss1: 4.887478892e-03,loss2: 8.486790955e-02 Loss3: 1.962527275e+01\n",
      "It: 780, Loss1: 4.873648752e-03,loss2: 8.468432724e-02 Loss3: 1.950519753e+01\n",
      "It: 800, Loss1: 5.787065718e-03,loss2: 8.678773791e-02 Loss3: 1.937796021e+01\n",
      "It: 820, Loss1: 5.697298795e-03,loss2: 8.889242262e-02 Loss3: 1.923136330e+01\n",
      "It: 840, Loss1: 6.181082688e-03,loss2: 9.028381109e-02 Loss3: 1.909506607e+01\n",
      "It: 860, Loss1: 5.063030869e-03,loss2: 9.067928791e-02 Loss3: 1.894719505e+01\n",
      "It: 880, Loss1: 4.800474737e-03,loss2: 9.138421714e-02 Loss3: 1.888422775e+01\n",
      "It: 900, Loss1: 4.265482537e-03,loss2: 9.134310484e-02 Loss3: 1.884083176e+01\n",
      "It: 920, Loss1: 4.420950543e-03,loss2: 9.306480736e-02 Loss3: 1.870135307e+01\n",
      "It: 940, Loss1: 4.258279223e-03,loss2: 9.211040288e-02 Loss3: 1.864696503e+01\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 4.414582\n",
      "  Number of iterations: 792\n",
      "  Number of functions evaluations: 943\n",
      "It: 20, Loss1: 4.257550463e-03,loss2: 9.225378931e-02 Loss3: 1.864571571e+01\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 18.742228\n",
      "  Number of iterations: 3\n",
      "  Number of functions evaluations: 24\n"
     ]
    }
   ],
   "source": [
    "LOSS1,LOSS2=model.train(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431bac16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二范数Error u: 6.132326e-04\n",
      "平均绝对Error u: 8.874401e-02\n",
      "无穷范数Error u: 7.385745e-01\n"
     ]
    }
   ],
   "source": [
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_pred, f_u_pred = model.predict(X_star)\n",
    "u_star = res.T.flatten()[:,None]  \n",
    "error_u1 = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_u2 = np.linalg.norm(u_star-u_pred,1)/len(u_star)\n",
    "error_u3 = np.linalg.norm(u_star-u_pred,np.inf)\n",
    "print('二范数Error u: %e' % (error_u1))\n",
    "print('平均绝对Error u: %e' % (error_u2))\n",
    "print('无穷范数Error u: %e' % (error_u3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d653388",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"f_u.mat\", {'f_u': f_u_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0faa74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"1.mat\", {'u': u_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649629e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67522a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d466c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "        scipy.io.savemat(\"f_u.mat\", {'f_u': f_u_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cbf23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d95819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfcpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
