{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "942ae41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82eca8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3deccd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x0, u0, tb, X_f, layers, lb, ub,u_lb,u_ub):\n",
    "        \n",
    "        #    lb = np.array([-1, 0])      ub = np.array([1, 1])\n",
    "        \n",
    "        X0 = np.concatenate((x0, 0*x0+0.0), 1)              #    初始     \n",
    "        X_lb = np.concatenate((0*tb + lb[0], tb), 1)    #    边界-1\n",
    "        X_ub = np.concatenate((0*tb + ub[0], tb), 1)    #    边界+1    \n",
    "        \n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "               \n",
    "        self.x0 = X0[:,0:1]\n",
    "        self.t0 = X0[:,1:2]\n",
    "\n",
    "        self.x_lb = X_lb[:,0:1]\n",
    "        self.t_lb = X_lb[:,1:2]\n",
    "        self.hsadasjd=1\n",
    "\n",
    "        self.x_ub = X_ub[:,0:1]\n",
    "        self.t_ub = X_ub[:,1:2]\n",
    "        \n",
    "        self.x_f = X_f[:,0:1]\n",
    "        self.t_f = X_f[:,1:2]\n",
    "        self.u_lb=u_lb\n",
    "        self.u_ub=u_ub\n",
    "        #分别是初始时刻的实部和虚部\n",
    "        self.u0 = u0\n",
    "        self.losslossloss=[]\n",
    "        # Initialize NNs\n",
    "        self.layers = layers\n",
    "        #返回初始的权重w和偏差b\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        # tf Placeholders\n",
    "        #形参 占位符，行数不确定，列数确定为1\n",
    "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, self.x0.shape[1]])\n",
    "        self.t0_tf = tf.placeholder(tf.float32, shape=[None, self.t0.shape[1]])\n",
    "        self.u_lb_tf = tf.placeholder(tf.float32, shape=[None, self.u_lb.shape[1]])\n",
    "        self.u_ub_tf = tf.placeholder(tf.float32, shape=[None, self.u_ub.shape[1]])\n",
    "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, self.u0.shape[1]])\n",
    "        self.x_lb_tf = tf.placeholder(tf.float32, shape=[None, self.x_lb.shape[1]])\n",
    "        self.t_lb_tf = tf.placeholder(tf.float32, shape=[None, self.t_lb.shape[1]])\n",
    "        self.x_ub_tf = tf.placeholder(tf.float32, shape=[None, self.x_ub.shape[1]])\n",
    "        self.t_ub_tf = tf.placeholder(tf.float32, shape=[None, self.t_ub.shape[1]])\n",
    "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
    "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, self.t_f.shape[1]])\n",
    "\n",
    "        # tf Graphs  进行预测\n",
    "        self.u0_pred= self.net_uv(self.x0_tf, self.t0_tf)\n",
    "        self.u_lb_pred= self.net_uv(self.x_lb_tf, self.t_lb_tf)\n",
    "        self.u_ub_pred = self.net_uv(self.x_ub_tf, self.t_ub_tf)\n",
    "        self.f_u_pred= self.net_f_uv(self.x_f_tf, self.t_f_tf)\n",
    "        \n",
    "    \n",
    "        \n",
    "        # Loss   8个损失函数相加\n",
    "        self.loss3=tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred))\n",
    "        \n",
    "        self.loss2=tf.reduce_mean(tf.square(self.f_u_pred))\n",
    "                \n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.f_u_pred))   \n",
    " \n",
    "        self.loss4 = tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +\\\n",
    "                        tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))\n",
    "\n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 100000,\n",
    "                                                                           'maxfun': 100000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "        \n",
    "\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "                \n",
    "        # tf session  配置Session运行参数&&GPU设备指定）\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        #初始化模型的参数\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        #产生截断正态分布随机数，stddev是标准差，取值范围为[ 0 - 2 * stddev, 0+2 * stddev ]\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        \n",
    "        #将初始输入X映射到-1到1之间为H\n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return Y\n",
    "    \n",
    "    def net_uv(self, x, t):\n",
    "        X = tf.concat([x,t],1)\n",
    "        \n",
    "        uv = self.neural_net(X, self.weights, self.biases)\n",
    "        \n",
    "        hhhhhh=0.15\n",
    "        \n",
    "        \n",
    "        UV = t*(1-x**2)*uv+(1-x**2)*tf.exp(1/(1+hhhhhh))\n",
    "\n",
    "\n",
    "        return UV\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def net_f_uv(self, x, t):\n",
    "        \n",
    "        u = self.net_uv(x,t)       \n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        \n",
    "        hhhhhh=0.15\n",
    "        f_u = u_t-u_xx-2*tf.exp(1/((2*t-1)*(2*t-1)+hhhhhh))+tf.exp(1/((2*t-1)*(2*t-1)+hhhhhh))*(1-x*x)*4*(2*t-1)/((2*t-1)*(2*t-1)+hhhhhh)/((2*t-1)*(2*t-1)+hhhhhh)\n",
    "        #f_u=u-tf.exp(1/((2*t-1)*(2*t-1)+0.5))*(1-x*x)\n",
    "        #return f_u/1319.919299519142\n",
    "        return f_u\n",
    "    \n",
    "    def callback(self, loss,f_u_pred,u0_pred,u_ub_pred,u_lb_pred):\n",
    "        \n",
    "        self.losslossloss.append(loss)\n",
    "            #losslossloss2\n",
    "        sss=self.hsadasjd\n",
    "        if sss%200==0:\n",
    "            losssss =tf.reduce_mean(tf.square(f_u_pred))\n",
    "            array1 = losssss.eval(session=tf.Session())        \n",
    "            tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        \n",
    "            loss1123456=self.u0_tf\n",
    "            lossskdajsdkas=self.sess.run(loss1123456, tf_dict)\n",
    "            zkjxJXhz = tf.reduce_mean(tf.square(lossskdajsdkas - u0_pred))\n",
    "            array2 = zkjxJXhz.eval(session=tf.Session())\n",
    "        \n",
    "            loss1123456=self.u_ub_tf\n",
    "            lssss1=self.sess.run(loss1123456, tf_dict)\n",
    "            loss112345sds6=self.u_lb_tf\n",
    "            sadsk=self.sess.run(loss112345sds6, tf_dict)            \n",
    "            \n",
    "            zkjxJXhzs = tf.reduce_mean(tf.square( lssss1- u_ub_pred))+tf.reduce_mean(tf.square(sadsk  - u_lb_pred))\n",
    "            array4 = zkjxJXhzs.eval(session=tf.Session())\n",
    "            print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e' % \n",
    "                      (sss,array2,array4,array1))\n",
    "            \n",
    "            log5=open(\"log5.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array2,file=log5)\n",
    "            log5.close() \n",
    "            log6=open(\"log6.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array4,file=log6)\n",
    "            log6.close()            \n",
    "            log7=open(\"log7.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array1,file=log7)\n",
    "            log7.close()            \n",
    "            \n",
    "            \n",
    "\n",
    "        sss=sss+1\n",
    "        self.hsadasjd=sss    \n",
    "    \n",
    "    def train(self, nIter):   \n",
    "        tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        lossloss1 = []\n",
    "        lossloss2 = []\n",
    "        lossloss3=[]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        loss_value11 = self.sess.run(self.loss3, tf_dict)\n",
    "        lossloss1.append(loss_value11)\n",
    "        \n",
    "        loss_value22 = self.sess.run(self.loss2, tf_dict)\n",
    "        lossloss2.append(loss_value22)\n",
    "        \n",
    "        loss_value33 = self.sess.run(self.loss4, tf_dict)\n",
    "        lossloss3.append(loss_value33)\n",
    "        \n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            # Print\n",
    "            if it % 200 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                \n",
    "                loss_value11 = self.sess.run(self.loss3, tf_dict)\n",
    "                lossloss1.append(loss_value11)\n",
    "                \n",
    "                loss_value22 = self.sess.run(self.loss2, tf_dict)\n",
    "                lossloss2.append(loss_value22)\n",
    "                \n",
    "                loss_value33 = self.sess.run(self.loss4, tf_dict)\n",
    "                lossloss3.append(loss_value33)\n",
    "                \n",
    "                print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e,Time: %.2f' % \n",
    "                      (it, loss_value11,loss_value33,loss_value22, elapsed))\n",
    "                start_time = time.time()\n",
    "                log1=open(\"log1.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "                print(loss_value11,file=log1)\n",
    "                log1.close()\n",
    "                log2=open(\"log2.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "                print(loss_value33,file=log2)\n",
    "                log2.close()\n",
    "                log3=open(\"log3.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "                print(loss_value22,file=log3)\n",
    "                log3.close()\n",
    "                \n",
    "                \n",
    "\n",
    "        self.optimizer.minimize(self.sess, \n",
    "                                feed_dict = tf_dict, \n",
    "                                fetches = [self.loss,self.f_u_pred,self.u0_pred,self.u_ub_pred,self.u_lb_pred], \n",
    "                                loss_callback = self.callback\n",
    "                               )    \n",
    "        \n",
    "        \n",
    "           \n",
    "        \n",
    "        return lossloss1,lossloss2\n",
    "    \n",
    "    def predict(self, X_star):\n",
    "        \n",
    "        tf_dict = {self.x0_tf: X_star[:,0:1], self.t0_tf: X_star[:,1:2]}\n",
    "        \n",
    "        u_star = self.sess.run(self.u0_pred, tf_dict)  \n",
    "        \n",
    "        \n",
    "        tf_dict = {self.x_f_tf: X_star[:,0:1], self.t_f_tf: X_star[:,1:2]}\n",
    "        \n",
    "        f_u_star = self.sess.run(self.f_u_pred, tf_dict)\n",
    "               \n",
    "        return u_star,f_u_star\n",
    "    def loss_show(self):\n",
    "        return self.losslossloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d30cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatsolution(x,t):\n",
    "    return math.exp(1/((2*t-1)**2+0.15))*(1-x**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac83c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "         \n",
    "    \n",
    "    # Doman bounds\n",
    "    lb = np.array([-1, 0])\n",
    "    ub = np.array([1, 1])\n",
    "\n",
    "    N0 = 1200                                      #初始点\n",
    "    N_b = 1200                                     #边界点\n",
    "    N_f = 10000                                #适配点\n",
    "    layers = [2,50,50,50,50,1]  \n",
    "    #读取真实解\n",
    "    x=np.linspace(-1,1,1200).flatten()[:,None]   \n",
    "    t=np.linspace(0,1,1200).flatten()[:,None]   \n",
    "    res=np.zeros([len(x),len(t)])  \n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(t)):\n",
    "            res[i,j]=heatsolution(x[i],t[j])\n",
    "    \n",
    "    \n",
    "    X, T = np.meshgrid(x, t)\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    #选定初始点N0=700个点\n",
    "    idx_x = np.random.choice(x.shape[0], N0, replace=False)   \n",
    "    x0 = x[idx_x,:]\n",
    "    u0 = res[idx_x,0:1]\n",
    "    #选择N_b=700个边界点\n",
    "    idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "    tb = t[idx_t,:]\n",
    "    u_lb = res[0,idx_t]\n",
    "    u_ub=res[-1,idx_t]\n",
    "    #N_f=2500个随机搭配点   第一列位置 第二列时间\n",
    "    X_f = lb + (ub-lb)*lhs(2, N_f)\n",
    "    x0=np.array(x0).flatten()[:,None]\n",
    "    u0=np.array(u0).flatten()[:,None]\n",
    "    u_lb=np.array(u_lb).flatten()[:,None]\n",
    "    u_ub=np.array(u_ub).flatten()[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eddc3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PhysicsInformedNN(x0, u0,tb, X_f, layers, lb, ub,u_lb,u_ub)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f216e0c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 4.845863500e+06,Time: 4.39\n",
      "It: 200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 4.651052000e+06,Time: 19.28\n",
      "It: 400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 4.549247000e+06,Time: 18.68\n",
      "It: 600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 4.444671000e+06,Time: 19.79\n",
      "It: 800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 4.342365500e+06,Time: 18.40\n",
      "It: 1000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 4.243203000e+06,Time: 18.47\n",
      "It: 1200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 4.149417250e+06,Time: 18.60\n",
      "It: 1400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 4.073335500e+06,Time: 18.37\n",
      "It: 1600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 4.013675250e+06,Time: 19.90\n",
      "It: 1800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.963471500e+06,Time: 24.86\n",
      "It: 200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.619627000e+06\n",
      "It: 400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.453143500e+06\n",
      "It: 600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.330051500e+06\n",
      "It: 800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.276472000e+06\n",
      "It: 1000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.236335750e+06\n",
      "It: 1200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.206144000e+06\n",
      "It: 1400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.176404500e+06\n",
      "It: 1600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.153381250e+06\n",
      "It: 1800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.107104000e+06\n",
      "It: 2000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.088418500e+06\n",
      "It: 2200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.075289500e+06\n",
      "It: 2400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.061235250e+06\n",
      "It: 2600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.046906750e+06\n",
      "It: 2800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.036781750e+06\n",
      "It: 3000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.020934250e+06\n",
      "It: 3200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 3.007575000e+06\n",
      "It: 3400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.998832000e+06\n",
      "It: 3600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.987714250e+06\n",
      "It: 3800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.976123250e+06\n",
      "It: 4000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.967109750e+06\n",
      "It: 4200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.956827000e+06\n",
      "It: 4400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.944871500e+06\n",
      "It: 4600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.925586000e+06\n",
      "It: 4800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.904780750e+06\n",
      "It: 5000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.894978750e+06\n",
      "It: 5200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.884339500e+06\n",
      "It: 5400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.872044750e+06\n",
      "It: 5600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.862111250e+06\n",
      "It: 5800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.850873250e+06\n",
      "It: 6000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.832967500e+06\n",
      "It: 6200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.776974000e+06\n",
      "It: 6400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.643175500e+06\n",
      "It: 6600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.548788750e+06\n",
      "It: 6800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.483753750e+06\n",
      "It: 7000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.449938750e+06\n",
      "It: 7200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.319198500e+06\n",
      "It: 7400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.249238750e+06\n",
      "It: 7600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.185396250e+06\n",
      "It: 7800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.141208250e+06\n",
      "It: 8000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.106973000e+06\n",
      "It: 8200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.066535250e+06\n",
      "It: 8400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 2.023603000e+06\n",
      "It: 8600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.980710500e+06\n",
      "It: 8800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.949290250e+06\n",
      "It: 9000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.924102125e+06\n",
      "It: 9200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.882504000e+06\n",
      "It: 9400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.855615000e+06\n",
      "It: 9600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.832566375e+06\n",
      "It: 9800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.802708625e+06\n",
      "It: 10000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.780992375e+06\n",
      "It: 10200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.749521250e+06\n",
      "It: 10400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.718102375e+06\n",
      "It: 10600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.691042000e+06\n",
      "It: 10800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.668967875e+06\n",
      "It: 11000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.649043875e+06\n",
      "It: 11200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.630611625e+06\n",
      "It: 11400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.606744125e+06\n",
      "It: 11600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.585521500e+06\n",
      "It: 11800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.566227750e+06\n",
      "It: 12000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.549803125e+06\n",
      "It: 12200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.538021125e+06\n",
      "It: 12400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.526915875e+06\n",
      "It: 12600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.515364750e+06\n",
      "It: 12800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.505564250e+06\n",
      "It: 13000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.497015250e+06\n",
      "It: 13200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.489126625e+06\n",
      "It: 13400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.480525000e+06\n",
      "It: 13600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.473927625e+06\n",
      "It: 13800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.467214500e+06\n",
      "It: 14000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.461146250e+06\n",
      "It: 14200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.455351875e+06\n",
      "It: 14400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.448435500e+06\n",
      "It: 14600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.442101000e+06\n",
      "It: 14800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.435315000e+06\n",
      "It: 15000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.429108000e+06\n",
      "It: 15200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.424824875e+06\n",
      "It: 15400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.421133875e+06\n",
      "It: 15600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.416406125e+06\n",
      "It: 15800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.412839125e+06\n",
      "It: 16000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.409057375e+06\n",
      "It: 16200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.403758125e+06\n",
      "It: 16400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.399276750e+06\n",
      "It: 16600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.395534500e+06\n",
      "It: 16800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.391956250e+06\n",
      "It: 17000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.388692000e+06\n",
      "It: 17200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.385709875e+06\n",
      "It: 17400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.382306875e+06\n",
      "It: 17600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.378927250e+06\n",
      "It: 17800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.376686125e+06\n",
      "It: 18000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.373883000e+06\n",
      "It: 18200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.371326625e+06\n",
      "It: 18400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.369422625e+06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 18600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.367838250e+06\n",
      "It: 18800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.365731125e+06\n",
      "It: 19000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.363095000e+06\n",
      "It: 19200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.360776125e+06\n",
      "It: 19400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.357821750e+06\n",
      "It: 19600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.354945375e+06\n",
      "It: 19800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.352302000e+06\n",
      "It: 20000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.350217125e+06\n",
      "It: 20200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.347213125e+06\n",
      "It: 20400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.344588375e+06\n",
      "It: 20600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.341993375e+06\n",
      "It: 20800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.338420250e+06\n",
      "It: 21000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.335766375e+06\n",
      "It: 21200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.332459000e+06\n",
      "It: 21400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.329334125e+06\n",
      "It: 21600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.325542750e+06\n",
      "It: 21800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.323451000e+06\n",
      "It: 22000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.318262000e+06\n",
      "It: 22200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.314083875e+06\n",
      "It: 22400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.308676500e+06\n",
      "It: 22600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.303871875e+06\n",
      "It: 22800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.297973500e+06\n",
      "It: 23000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.289669125e+06\n",
      "It: 23200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.280609875e+06\n",
      "It: 23400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.272722000e+06\n",
      "It: 23600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.263232875e+06\n",
      "It: 23800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.255952375e+06\n",
      "It: 24000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.246557875e+06\n",
      "It: 24200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.239924375e+06\n",
      "It: 24400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.232520875e+06\n",
      "It: 24600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.224429000e+06\n",
      "It: 24800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.216914875e+06\n",
      "It: 25000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.209696625e+06\n",
      "It: 25200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.204787875e+06\n",
      "It: 25400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.198202000e+06\n",
      "It: 25600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.188836375e+06\n",
      "It: 25800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.182341500e+06\n",
      "It: 26000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.175059500e+06\n",
      "It: 26200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.167645125e+06\n",
      "It: 26400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.161256750e+06\n",
      "It: 26600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.154305000e+06\n",
      "It: 26800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.148385125e+06\n",
      "It: 27000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.142003250e+06\n",
      "It: 27200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.135792500e+06\n",
      "It: 27400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.129152750e+06\n",
      "It: 27600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.123529375e+06\n",
      "It: 27800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.117866875e+06\n",
      "It: 28000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.111239500e+06\n",
      "It: 28200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.105619125e+06\n",
      "It: 28400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.100034000e+06\n",
      "It: 28600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.093699750e+06\n",
      "It: 28800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.089402500e+06\n",
      "It: 29000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.086594250e+06\n",
      "It: 29200, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.083912250e+06\n",
      "It: 29400, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.080539500e+06\n",
      "It: 29600, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.078214500e+06\n",
      "It: 29800, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.075895250e+06\n",
      "It: 30000, Loss1: 7.937882021e-15,loss2: 0.000000000e+00 Loss3: 1.073590625e+06\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 1073020.875000\n",
      "  Number of iterations: 27336\n",
      "  Number of functions evaluations: 30063\n"
     ]
    }
   ],
   "source": [
    "LOSS1,LOSS2=model.train(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4768869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二范数Error u: 1.138144e+00\n",
      "平均绝对Error u: 1.572058e+02\n",
      "无穷范数Error u: 6.568105e+02\n"
     ]
    }
   ],
   "source": [
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_pred, f_u_pred = model.predict(X_star)\n",
    "u_star = res.T.flatten()[:,None]  \n",
    "error_u1 = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_u2 = np.linalg.norm(u_star-u_pred,1)/len(u_star)\n",
    "error_u3 = np.linalg.norm(u_star-u_pred,np.inf)\n",
    "print('二范数Error u: %e' % (error_u1))\n",
    "print('平均绝对Error u: %e' % (error_u2))\n",
    "print('无穷范数Error u: %e' % (error_u3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f5da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"3.mat\", {'f_u': f_u_pred})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb39209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5431a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfcpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
