{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "942ae41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82eca8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "np.random.seed(1236)\n",
    "tf.set_random_seed(1236)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3deccd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x0, u0, tb, X_f, layers, lb, ub,u_lb,u_ub):\n",
    "        \n",
    "        #    lb = np.array([-1, 0])      ub = np.array([1, 1])\n",
    "        \n",
    "        X0 = np.concatenate((x0, 0*x0+0.0), 1)              #    初始     \n",
    "        X_lb = np.concatenate((0*tb + lb[0], tb), 1)    #    边界-1\n",
    "        X_ub = np.concatenate((0*tb + ub[0], tb), 1)    #    边界+1    \n",
    "        \n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "               \n",
    "        self.x0 = X0[:,0:1]\n",
    "        self.t0 = X0[:,1:2]\n",
    "\n",
    "        self.x_lb = X_lb[:,0:1]\n",
    "        self.t_lb = X_lb[:,1:2]\n",
    "        self.hsadasjd=1\n",
    "\n",
    "        self.x_ub = X_ub[:,0:1]\n",
    "        self.t_ub = X_ub[:,1:2]\n",
    "        \n",
    "        self.x_f = X_f[:,0:1]\n",
    "        self.t_f = X_f[:,1:2]\n",
    "        self.u_lb=u_lb\n",
    "        self.u_ub=u_ub\n",
    "        #分别是初始时刻的实部和虚部\n",
    "        self.u0 = u0\n",
    "        self.losslossloss=[]\n",
    "        # Initialize NNs\n",
    "        self.layers = layers\n",
    "        #返回初始的权重w和偏差b\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        # tf Placeholders\n",
    "        #形参 占位符，行数不确定，列数确定为1\n",
    "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, self.x0.shape[1]])\n",
    "        self.t0_tf = tf.placeholder(tf.float32, shape=[None, self.t0.shape[1]])\n",
    "        self.u_lb_tf = tf.placeholder(tf.float32, shape=[None, self.u_lb.shape[1]])\n",
    "        self.u_ub_tf = tf.placeholder(tf.float32, shape=[None, self.u_ub.shape[1]])\n",
    "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, self.u0.shape[1]])\n",
    "        self.x_lb_tf = tf.placeholder(tf.float32, shape=[None, self.x_lb.shape[1]])\n",
    "        self.t_lb_tf = tf.placeholder(tf.float32, shape=[None, self.t_lb.shape[1]])\n",
    "        self.x_ub_tf = tf.placeholder(tf.float32, shape=[None, self.x_ub.shape[1]])\n",
    "        self.t_ub_tf = tf.placeholder(tf.float32, shape=[None, self.t_ub.shape[1]])\n",
    "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
    "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, self.t_f.shape[1]])\n",
    "\n",
    "        # tf Graphs  进行预测\n",
    "        self.u0_pred= self.net_uv(self.x0_tf, self.t0_tf)\n",
    "        self.u_lb_pred= self.net_uv(self.x_lb_tf, self.t_lb_tf)\n",
    "        self.u_ub_pred = self.net_uv(self.x_ub_tf, self.t_ub_tf)\n",
    "        self.f_u_pred= self.net_f_uv(self.x_f_tf, self.t_f_tf)\n",
    "        \n",
    "        # Loss   8个损失函数相加\n",
    "        self.loss3=tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred))\n",
    "        \n",
    "        self.loss2=tf.reduce_mean(tf.square(self.f_u_pred))\n",
    "                \n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred))+ \\\n",
    "                    (tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) + \\\n",
    "                    tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))) + \\\n",
    "                    tf.reduce_mean(tf.square(self.f_u_pred))   \n",
    " \n",
    "        self.loss4 = tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +\\\n",
    "                        tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))\n",
    "\n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 100000,\n",
    "                                                                           'maxfun': 100000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "        \n",
    "\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "                \n",
    "        # tf session  配置Session运行参数&&GPU设备指定）\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        #初始化模型的参数\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        #产生截断正态分布随机数，stddev是标准差，取值范围为[ 0 - 2 * stddev, 0+2 * stddev ]\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        \n",
    "        #将初始输入X映射到-1到1之间为H\n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "    \n",
    "    def net_uv(self, x, t):\n",
    "        X = tf.concat([x,t],1)\n",
    "        \n",
    "        uv = self.neural_net(X, self.weights, self.biases)\n",
    "\n",
    "\n",
    "        return uv\n",
    "    \n",
    "    \n",
    "    \n",
    "    def net_f_uv(self, x, t):\n",
    "        \n",
    "        u = self.net_uv(x,t)       \n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        \n",
    "        hhhhhh=0.3\n",
    "        f_u = u_t-u_xx-2*tf.exp(1/((2*t-1)*(2*t-1)+hhhhhh))+tf.exp(1/((2*t-1)*(2*t-1)+hhhhhh))*(1-x*x)*4*(2*t-1)/((2*t-1)*(2*t-1)+hhhhhh)/((2*t-1)*(2*t-1)+hhhhhh)\n",
    "        #f_u=u-tf.exp(1/((2*t-1)*(2*t-1)+0.5))*(1-x*x)\n",
    "        #return f_u/1319.919299519142\n",
    "        return f_u\n",
    "    \n",
    "    def callback(self, loss,f_u_pred,u0_pred,u_ub_pred,u_lb_pred):\n",
    "        \n",
    "        self.losslossloss.append(loss)\n",
    "            #losslossloss2\n",
    "        sss=self.hsadasjd\n",
    "        if sss%200==0:\n",
    "            losssss =tf.reduce_mean(tf.square(f_u_pred))\n",
    "            array1 = losssss.eval(session=tf.Session())        \n",
    "            tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        \n",
    "            loss1123456=self.u0_tf\n",
    "            lossskdajsdkas=self.sess.run(loss1123456, tf_dict)\n",
    "            zkjxJXhz = tf.reduce_mean(tf.square(lossskdajsdkas - u0_pred))\n",
    "            array2 = zkjxJXhz.eval(session=tf.Session())\n",
    "        \n",
    "            loss1123456=self.u_ub_tf\n",
    "            lssss1=self.sess.run(loss1123456, tf_dict)\n",
    "            loss112345sds6=self.u_lb_tf\n",
    "            sadsk=self.sess.run(loss112345sds6, tf_dict)            \n",
    "            \n",
    "            zkjxJXhzs = tf.reduce_mean(tf.square( lssss1- u_ub_pred))+tf.reduce_mean(tf.square(sadsk  - u_lb_pred))\n",
    "            array4 = zkjxJXhzs.eval(session=tf.Session())\n",
    "            print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e' % \n",
    "                      (sss,array2,array4,array1))\n",
    "\n",
    "        sss=sss+1\n",
    "        self.hsadasjd=sss    \n",
    "    \n",
    "    def train(self, nIter):   \n",
    "        tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        lossloss1 = []\n",
    "        lossloss2 = []\n",
    "        lossloss3=[]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        loss_value11 = self.sess.run(self.loss3, tf_dict)\n",
    "        lossloss1.append(loss_value11)\n",
    "        \n",
    "        loss_value22 = self.sess.run(self.loss2, tf_dict)\n",
    "        lossloss2.append(loss_value22)\n",
    "        \n",
    "        loss_value33 = self.sess.run(self.loss4, tf_dict)\n",
    "        lossloss3.append(loss_value33)\n",
    "        \n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            # Print\n",
    "            if it % 200 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                \n",
    "                loss_value11 = self.sess.run(self.loss3, tf_dict)\n",
    "                lossloss1.append(loss_value11)\n",
    "                \n",
    "                loss_value22 = self.sess.run(self.loss2, tf_dict)\n",
    "                lossloss2.append(loss_value22)\n",
    "                \n",
    "                loss_value33 = self.sess.run(self.loss4, tf_dict)\n",
    "                lossloss3.append(loss_value33)\n",
    "                \n",
    "                print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e,Time: %.2f' % \n",
    "                      (it, loss_value11,loss_value33,loss_value22, elapsed))\n",
    "                start_time = time.time()\n",
    "\n",
    "                \n",
    "                \n",
    "\n",
    "        self.optimizer.minimize(self.sess, \n",
    "                                feed_dict = tf_dict, \n",
    "                                fetches = [self.loss,self.f_u_pred,self.u0_pred,self.u_ub_pred,self.u_lb_pred], \n",
    "                                loss_callback = self.callback\n",
    "                               )    \n",
    "        \n",
    "        \n",
    "           \n",
    "        \n",
    "        return lossloss1,lossloss2\n",
    "    \n",
    "    def predict(self, X_star):\n",
    "        \n",
    "        tf_dict = {self.x0_tf: X_star[:,0:1], self.t0_tf: X_star[:,1:2]}\n",
    "        \n",
    "        u_star = self.sess.run(self.u0_pred, tf_dict)  \n",
    "        \n",
    "        \n",
    "        tf_dict = {self.x_f_tf: X_star[:,0:1], self.t_f_tf: X_star[:,1:2]}\n",
    "        \n",
    "        f_u_star = self.sess.run(self.f_u_pred, tf_dict)\n",
    "               \n",
    "        return u_star,f_u_star\n",
    "    def loss_show(self):\n",
    "        return self.losslossloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d30cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatsolution(x,t):\n",
    "    return math.exp(1/((2*t-1)**2+0.3))*(1-x**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac83c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "         \n",
    "    \n",
    "    # Doman bounds\n",
    "    lb = np.array([-1, 0])\n",
    "    ub = np.array([1, 1])\n",
    "\n",
    "    N0 = 700                                      #初始点\n",
    "    N_b = 700                                     #边界点\n",
    "    N_f = 3000                              #适配点\n",
    "    layers = [2,20,20,20,20,1]  \n",
    "    #读取真实解\n",
    "    x=np.linspace(-1,1,700).flatten()[:,None]   \n",
    "    t=np.linspace(0,1,700).flatten()[:,None]   \n",
    "    res=np.zeros([len(x),len(t)])  \n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(t)):\n",
    "            res[i,j]=heatsolution(x[i],t[j])\n",
    "    \n",
    "    \n",
    "    X, T = np.meshgrid(x, t)\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    #选定初始点N0=700个点\n",
    "    idx_x = np.random.choice(x.shape[0], N0, replace=False)   \n",
    "    x0 = x[idx_x,:]\n",
    "    u0 = res[idx_x,0:1]\n",
    "    #选择N_b=700个边界点\n",
    "    idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "    tb = t[idx_t,:]\n",
    "    u_lb = res[0,idx_t]\n",
    "    u_ub=res[-1,idx_t]\n",
    "    #N_f=2500个随机搭配点   第一列位置 第二列时间\n",
    "    X_f = lb + (ub-lb)*lhs(2, N_f)\n",
    "    x0=np.array(x0).flatten()[:,None]\n",
    "    u0=np.array(u0).flatten()[:,None]\n",
    "    u_lb=np.array(u_lb).flatten()[:,None]\n",
    "    u_ub=np.array(u_ub).flatten()[:,None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eddc3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PhysicsInformedNN(x0, u0,tb, X_f, layers, lb, ub,u_lb,u_ub)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f216e0c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss1: 2.416193485e+00,loss2: 3.098399611e-03 Loss3: 3.090304443e+03,Time: 0.69\n",
      "It: 200, Loss1: 8.586891937e+01,loss2: 1.088006897e+02 Loss3: 9.578444824e+02,Time: 1.32\n",
      "It: 400, Loss1: 1.186614609e+02,loss2: 1.617675629e+02 Loss3: 7.252429810e+02,Time: 1.26\n",
      "It: 600, Loss1: 1.252865982e+02,loss2: 1.795179596e+02 Loss3: 6.791889038e+02,Time: 1.28\n",
      "It: 800, Loss1: 1.233272629e+02,loss2: 1.850597076e+02 Loss3: 6.607377930e+02,Time: 1.25\n",
      "It: 1000, Loss1: 1.140905609e+02,loss2: 1.902201843e+02 Loss3: 6.490172729e+02,Time: 1.27\n",
      "It: 1200, Loss1: 9.683917236e+01,loss2: 1.778546448e+02 Loss3: 5.658496704e+02,Time: 1.25\n",
      "It: 1400, Loss1: 7.812200928e+01,loss2: 1.840991821e+02 Loss3: 4.113633423e+02,Time: 1.25\n",
      "It: 1600, Loss1: 6.632878113e+01,loss2: 1.859895477e+02 Loss3: 3.527904053e+02,Time: 1.25\n",
      "It: 1800, Loss1: 5.391086578e+01,loss2: 1.621510925e+02 Loss3: 2.231829987e+02,Time: 1.27\n",
      "It: 200, Loss1: 1.959552802e-02,loss2: 8.938030899e-02 Loss3: 1.737389714e-01\n",
      "It: 400, Loss1: 1.079706359e-03,loss2: 1.027161628e-02 Loss3: 5.569786578e-02\n",
      "It: 600, Loss1: 9.712995961e-04,loss2: 6.382095627e-03 Loss3: 2.603844926e-02\n",
      "It: 800, Loss1: 4.191586049e-04,loss2: 4.891725257e-03 Loss3: 1.345258113e-02\n",
      "It: 1000, Loss1: 4.711611837e-04,loss2: 3.469565418e-03 Loss3: 8.756765164e-03\n",
      "It: 1200, Loss1: 4.234311345e-04,loss2: 2.640183084e-03 Loss3: 7.682016585e-03\n",
      "It: 1400, Loss1: 3.829895577e-04,loss2: 1.927573932e-03 Loss3: 6.687843241e-03\n",
      "It: 1600, Loss1: 4.257498367e-04,loss2: 1.431564451e-03 Loss3: 4.937846679e-03\n",
      "It: 1800, Loss1: 1.638314861e-04,loss2: 1.308987034e-03 Loss3: 4.077516962e-03\n",
      "It: 2000, Loss1: 5.425690688e-05,loss2: 1.077012392e-03 Loss3: 3.448601346e-03\n",
      "It: 2200, Loss1: 5.327790495e-05,loss2: 8.136928082e-04 Loss3: 3.020116827e-03\n",
      "It: 2400, Loss1: 1.933525164e-05,loss2: 7.663295255e-04 Loss3: 2.322847955e-03\n",
      "It: 2600, Loss1: 1.174438967e-05,loss2: 7.159115630e-04 Loss3: 1.913906890e-03\n",
      "It: 2800, Loss1: 4.488156719e-06,loss2: 6.928163930e-04 Loss3: 1.738940831e-03\n",
      "It: 3000, Loss1: 9.816531019e-06,loss2: 5.888254964e-04 Loss3: 1.557190786e-03\n",
      "It: 3200, Loss1: 8.047915799e-06,loss2: 4.987373250e-04 Loss3: 1.463399851e-03\n",
      "It: 3400, Loss1: 9.795403457e-06,loss2: 4.202516284e-04 Loss3: 1.370188082e-03\n",
      "It: 3600, Loss1: 6.098783160e-06,loss2: 3.568297834e-04 Loss3: 1.192802563e-03\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.001435\n",
      "  Number of iterations: 3434\n",
      "  Number of functions evaluations: 3740\n"
     ]
    }
   ],
   "source": [
    "LOSS1,LOSS2=model.train(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddcc662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二范数Error u: 5.272050e-04\n",
      "平均绝对Error u: 3.266696e-03\n",
      "无穷范数Error u: 4.699558e-02\n"
     ]
    }
   ],
   "source": [
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_pred, f_u_pred = model.predict(X_star)\n",
    "u_star = res.T.flatten()[:,None]  \n",
    "error_u1 = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_u2 = np.linalg.norm(u_star-u_pred,1)/len(u_star)\n",
    "error_u3 = np.linalg.norm(u_star-u_pred,np.inf)\n",
    "print('二范数Error u: %e' % (error_u1))\n",
    "print('平均绝对Error u: %e' % (error_u2))\n",
    "print('无穷范数Error u: %e' % (error_u3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb940ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"f_u.mat\", {'f_u': f_u_pred})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f5da2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7675cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfcpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
