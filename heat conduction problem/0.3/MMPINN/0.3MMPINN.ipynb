{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44a1c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "import time\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c80214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "np.random.seed(1235)\n",
    "tf.set_random_seed(1235)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b063bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicsInformedNN:\n",
    "    # Initialize the class\n",
    "    def __init__(self, x0, u0, tb, X_f, layers, lb, ub,u_lb,u_ub):\n",
    "        \n",
    "        #    lb = np.array([-1, 0])      ub = np.array([1, 1])\n",
    "        \n",
    "        X0 = np.concatenate((x0, 0*x0+0.0), 1)              #    初始     \n",
    "        X_lb = np.concatenate((0*tb + lb[0], tb), 1)    #    边界-1\n",
    "        X_ub = np.concatenate((0*tb + ub[0], tb), 1)    #    边界+1    \n",
    "        \n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "               \n",
    "        self.x0 = X0[:,0:1]\n",
    "        self.t0 = X0[:,1:2]\n",
    "\n",
    "        self.x_lb = X_lb[:,0:1]\n",
    "        self.t_lb = X_lb[:,1:2]\n",
    "        self.hsadasjd=1\n",
    "\n",
    "        self.x_ub = X_ub[:,0:1]\n",
    "        self.t_ub = X_ub[:,1:2]\n",
    "        \n",
    "        self.x_f = X_f[:,0:1]\n",
    "        self.t_f = X_f[:,1:2]\n",
    "        self.u_lb=u_lb\n",
    "        self.u_ub=u_ub\n",
    "        #分别是初始时刻的实部和虚部\n",
    "        self.u0 = u0\n",
    "        self.losslossloss=[]\n",
    "        # Initialize NNs\n",
    "        self.layers = layers\n",
    "        #返回初始的权重w和偏差b\n",
    "        self.weights, self.biases = self.initialize_NN(layers)\n",
    "        \n",
    "        # tf Placeholders\n",
    "        #形参 占位符，行数不确定，列数确定为1\n",
    "        self.x0_tf = tf.placeholder(tf.float32, shape=[None, self.x0.shape[1]])\n",
    "        self.t0_tf = tf.placeholder(tf.float32, shape=[None, self.t0.shape[1]])\n",
    "        self.u_lb_tf = tf.placeholder(tf.float32, shape=[None, self.u_lb.shape[1]])\n",
    "        self.u_ub_tf = tf.placeholder(tf.float32, shape=[None, self.u_ub.shape[1]])\n",
    "        self.u0_tf = tf.placeholder(tf.float32, shape=[None, self.u0.shape[1]])\n",
    "        self.x_lb_tf = tf.placeholder(tf.float32, shape=[None, self.x_lb.shape[1]])\n",
    "        self.t_lb_tf = tf.placeholder(tf.float32, shape=[None, self.t_lb.shape[1]])\n",
    "        self.x_ub_tf = tf.placeholder(tf.float32, shape=[None, self.x_ub.shape[1]])\n",
    "        self.t_ub_tf = tf.placeholder(tf.float32, shape=[None, self.t_ub.shape[1]])\n",
    "        self.x_f_tf = tf.placeholder(tf.float32, shape=[None, self.x_f.shape[1]])\n",
    "        self.t_f_tf = tf.placeholder(tf.float32, shape=[None, self.t_f.shape[1]])\n",
    "\n",
    "        # tf Graphs  进行预测\n",
    "        self.u0_pred= self.net_uv(self.x0_tf, self.t0_tf)\n",
    "        self.u_lb_pred= self.net_uv(self.x_lb_tf, self.t_lb_tf)\n",
    "        self.u_ub_pred = self.net_uv(self.x_ub_tf, self.t_ub_tf)\n",
    "        self.f_u_pred= self.net_f_uv(self.x_f_tf, self.t_f_tf)\n",
    "        \n",
    "        # Loss   8个损失函数相加\n",
    "        self.loss3=tf.pow(tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)),1/1)\n",
    "        \n",
    "        self.loss2=tf.pow(tf.reduce_mean(tf.square(self.f_u_pred)),1/1)\n",
    "                \n",
    "        \n",
    "        self.loss = tf.pow(tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)),1)+                     tf.pow((tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +                     tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))),1) +                     tf.pow(tf.reduce_mean(tf.square(self.f_u_pred)),1/3)   \n",
    "        self.lossss = tf.pow(tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)),1)+                     tf.pow((tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +                     tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))),1) +                     tf.pow(tf.reduce_mean(tf.square(self.f_u_pred)),1/2)  \n",
    "        self.lossss33 = tf.pow(tf.reduce_mean(tf.square(self.u0_tf - self.u0_pred)),1)+                     tf.pow((tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +                     tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))),1) +                     tf.pow(tf.reduce_mean(tf.square(self.f_u_pred)),1)  \n",
    "                        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.loss4 = tf.pow((tf.reduce_mean(tf.square(self.u_ub_tf  - self.u_ub_pred)) +                     tf.reduce_mean(tf.square(self.u_lb_tf  - self.u_lb_pred))),1/1)\n",
    "        \n",
    "        \n",
    "        # Optimizers  maxiter最大迭代次数  maxfun最大求值次数 maxcor int变量的最大数量\n",
    "        #maxls 可选的最大搜索步数\n",
    "        #maxls 可选的最大搜索步数\n",
    "        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 100000,\n",
    "                                                                           'maxfun': 100000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.optimizer11 = tf.contrib.opt.ScipyOptimizerInterface(self.lossss, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 100000,\n",
    "                                                                           'maxfun': 100000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "        \n",
    "        self.optimizer22 = tf.contrib.opt.ScipyOptimizerInterface(self.lossss33, \n",
    "                                                                method = 'L-BFGS-B', \n",
    "                                                                options = {'maxiter': 100000,\n",
    "                                                                           'maxfun': 100000,\n",
    "                                                                           'maxcor': 50,\n",
    "                                                                           'maxls': 50,\n",
    "                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        是一个寻找全局最优点的优化算法，引入了二次方梯度校正\n",
    "        除了利用反向传播算法对权重和偏置项进行修正外，也在运行中不断修正学习率。\n",
    "        根据其损失量学习自适应，损失量大则学习率大，进行修正的角度越大，损失量小，修正的幅度也小，学习率就小，\n",
    "        但是不会超过自己所设定的学习率。20\n",
    "        3\n",
    "        '''\n",
    "        self.optimizer_Adam = tf.train.AdamOptimizer()\n",
    "        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n",
    "                \n",
    "        # tf session  配置Session运行参数&&GPU设备指定）\n",
    "        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n",
    "                                                     log_device_placement=True))\n",
    "        #初始化模型的参数\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "    def initialize_NN(self, layers):        \n",
    "        weights = []\n",
    "        biases = []\n",
    "        num_layers = len(layers) \n",
    "        for l in range(0,num_layers-1):\n",
    "            W = self.xavier_init(size=[layers[l], layers[l+1]])\n",
    "            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n",
    "            weights.append(W)\n",
    "            biases.append(b)        \n",
    "        return weights, biases\n",
    "        \n",
    "    def xavier_init(self, size):\n",
    "        in_dim = size[0]\n",
    "        out_dim = size[1]        \n",
    "        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n",
    "        #产生截断正态分布随机数，stddev是标准差，取值范围为[ 0 - 2 * stddev, 0+2 * stddev ]\n",
    "        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n",
    "    \n",
    "    def neural_net(self, X, weights, biases):\n",
    "        num_layers = len(weights) + 1\n",
    "        \n",
    "        #将初始输入X映射到-1到1之间为H\n",
    "        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n",
    "        for l in range(0,num_layers-2):\n",
    "            W = weights[l]\n",
    "            b = biases[l]\n",
    "            H = tf.tanh(tf.add(tf.matmul(H, W), b))\n",
    "        W = weights[-1]\n",
    "        b = biases[-1]\n",
    "        Y = tf.add(tf.matmul(H, W), b)\n",
    "        return Y\n",
    "    \n",
    "    def net_uv(self, x, t):\n",
    "        X = tf.concat([x,t],1)\n",
    "        \n",
    "        uv = self.neural_net(X, self.weights, self.biases)\n",
    "\n",
    "\n",
    "        return uv\n",
    "    \n",
    "    \n",
    "    \n",
    "    def net_f_uv(self, x, t):\n",
    "        \n",
    "        u = self.net_uv(x,t)       \n",
    "        u_t = tf.gradients(u, t)[0]\n",
    "        u_x = tf.gradients(u, x)[0]\n",
    "        u_xx = tf.gradients(u_x, x)[0]\n",
    "        \n",
    "        hhhhhh=0.3\n",
    "        f_u = u_t-u_xx-2*tf.exp(1/((2*t-1)*(2*t-1)+hhhhhh))+tf.exp(1/((2*t-1)*(2*t-1)+hhhhhh))*(1-x*x)*4*(2*t-1)/((2*t-1)*(2*t-1)+hhhhhh)/((2*t-1)*(2*t-1)+hhhhhh)\n",
    "        #f_u=u-tf.exp(1/((2*t-1)*(2*t-1)+0.5))*(1-x*x)\n",
    "        #return f_u/1319.919299519142\n",
    "        return f_u\n",
    "    \n",
    "    def callback(self, loss,f_u_pred,u0_pred,u_ub_pred,u_lb_pred):\n",
    "        \n",
    "        self.losslossloss.append(loss)\n",
    "            #losslossloss2\n",
    "        sss=self.hsadasjd\n",
    "        if sss%200==0:\n",
    "            losssss =tf.reduce_mean(tf.square(f_u_pred))\n",
    "            array1 = losssss.eval(session=tf.Session())        \n",
    "            tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        \n",
    "            loss1123456=self.u0_tf\n",
    "            lossskdajsdkas=self.sess.run(loss1123456, tf_dict)\n",
    "            zkjxJXhz = tf.reduce_mean(tf.square(lossskdajsdkas - u0_pred))\n",
    "            array2 = zkjxJXhz.eval(session=tf.Session())\n",
    "        \n",
    "            loss1123456=self.u_ub_tf\n",
    "            lssss1=self.sess.run(loss1123456, tf_dict)\n",
    "            loss112345sds6=self.u_lb_tf\n",
    "            sadsk=self.sess.run(loss112345sds6, tf_dict)            \n",
    "            \n",
    "            zkjxJXhzs = tf.reduce_mean(tf.square( lssss1- u_ub_pred))+tf.reduce_mean(tf.square(sadsk  - u_lb_pred))\n",
    "            array4 = zkjxJXhzs.eval(session=tf.Session())\n",
    "            print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e' % \n",
    "                      (sss,array2,array4,array1))\n",
    "            log5=open(\"log5.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array2,file=log5)\n",
    "            log5.close() \n",
    "            log6=open(\"log6.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array4,file=log6)\n",
    "            log6.close()            \n",
    "            log7=open(\"log7.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "            print(array1,file=log7)\n",
    "            log7.close()\n",
    "        sss=sss+1\n",
    "        self.hsadasjd=sss\n",
    "    \n",
    "    \n",
    "    def callback11(self, lossss,f_u_pred,u0_pred,u_ub_pred,u_lb_pred):\n",
    "        \n",
    "        self.losslossloss.append(lossss)\n",
    "            #losslossloss2\n",
    "        sss=self.hsadasjd\n",
    "        if sss%20==0:\n",
    "            losssss =tf.reduce_mean(tf.square(f_u_pred))\n",
    "            array1 = losssss.eval(session=tf.Session())        \n",
    "            tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        \n",
    "            loss1123456=self.u0_tf\n",
    "            lossskdajsdkas=self.sess.run(loss1123456, tf_dict)\n",
    "            zkjxJXhz = tf.reduce_mean(tf.square(lossskdajsdkas - u0_pred))\n",
    "            array2 = zkjxJXhz.eval(session=tf.Session())\n",
    "        \n",
    "            loss1123456=self.u_ub_tf\n",
    "            lssss1=self.sess.run(loss1123456, tf_dict)\n",
    "            loss112345sds6=self.u_lb_tf\n",
    "            sadsk=self.sess.run(loss112345sds6, tf_dict)            \n",
    "            \n",
    "            zkjxJXhzs = tf.reduce_mean(tf.square( lssss1- u_ub_pred))+tf.reduce_mean(tf.square(sadsk  - u_lb_pred))\n",
    "            array4 = zkjxJXhzs.eval(session=tf.Session())\n",
    "            print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e' % \n",
    "                      (sss,array2,array4,array1))\n",
    "        sss=sss+1\n",
    "        self.hsadasjd=sss    \n",
    "    \n",
    "    \n",
    "    def callback22(self, lossss33,f_u_pred,u0_pred,u_ub_pred,u_lb_pred):\n",
    "        \n",
    "        self.losslossloss.append(lossss33)\n",
    "            #losslossloss2\n",
    "        sss=self.hsadasjd\n",
    "        if sss%20==0:\n",
    "            losssss =tf.reduce_mean(tf.square(f_u_pred))\n",
    "            array1 = losssss.eval(session=tf.Session())        \n",
    "            tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        \n",
    "            loss1123456=self.u0_tf\n",
    "            lossskdajsdkas=self.sess.run(loss1123456, tf_dict)\n",
    "            zkjxJXhz = tf.reduce_mean(tf.square(lossskdajsdkas - u0_pred))\n",
    "            array2 = zkjxJXhz.eval(session=tf.Session())\n",
    "        \n",
    "            loss1123456=self.u_ub_tf\n",
    "            lssss1=self.sess.run(loss1123456, tf_dict)\n",
    "            loss112345sds6=self.u_lb_tf\n",
    "            sadsk=self.sess.run(loss112345sds6, tf_dict)            \n",
    "            \n",
    "            zkjxJXhzs = tf.reduce_mean(tf.square( lssss1- u_ub_pred))+tf.reduce_mean(tf.square(sadsk  - u_lb_pred))\n",
    "            array4 = zkjxJXhzs.eval(session=tf.Session())\n",
    "            print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e' % \n",
    "                      (sss,array2,array4,array1))\n",
    "        sss=sss+1\n",
    "        self.hsadasjd=sss \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self, nIter):   \n",
    "        tf_dict = {self.x0_tf: self.x0, self.t0_tf: self.t0,\n",
    "                   self.u0_tf: self.u0,self.u_lb_tf:self.u_lb,self.u_ub_tf:self.u_ub,\n",
    "                   self.x_lb_tf: self.x_lb, self.t_lb_tf: self.t_lb,\n",
    "                   self.x_ub_tf: self.x_ub, self.t_ub_tf: self.t_ub,\n",
    "                   self.x_f_tf: self.x_f, self.t_f_tf: self.t_f}\n",
    "        lossloss1 = []\n",
    "        lossloss2 = []\n",
    "        lossloss3=[]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        loss_value11 = self.sess.run(self.loss3, tf_dict)\n",
    "        lossloss1.append(loss_value11)\n",
    "        \n",
    "        loss_value22 = self.sess.run(self.loss2, tf_dict)\n",
    "        lossloss2.append(loss_value22)\n",
    "        \n",
    "        loss_value33 = self.sess.run(self.loss4, tf_dict)\n",
    "        lossloss3.append(loss_value33)\n",
    "        \n",
    "        for it in range(nIter):\n",
    "            self.sess.run(self.train_op_Adam, tf_dict)\n",
    "            # Print\n",
    "            if it % 200 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                \n",
    "                loss_value11 = self.sess.run(self.loss3, tf_dict)\n",
    "                lossloss1.append(loss_value11)\n",
    "                \n",
    "                loss_value22 = self.sess.run(self.loss2, tf_dict)\n",
    "                lossloss2.append(loss_value22)\n",
    "                \n",
    "                loss_value33 = self.sess.run(self.loss4, tf_dict)\n",
    "                lossloss3.append(loss_value33)\n",
    "                \n",
    "                print('It: %d, Loss1: %.9e,loss2: %.9e Loss3: %.9e,Time: %.2f' % \n",
    "                      (it, loss_value11,loss_value33,loss_value22, elapsed))\n",
    "                start_time = time.time()\n",
    "                log1=open(\"log1.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "                print(loss_value11,file=log1)\n",
    "                log1.close()\n",
    "                log2=open(\"log2.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "                print(loss_value33,file=log2)\n",
    "                log2.close()\n",
    "                log3=open(\"log3.txt\",mode = 'a+', encoding = 'utf-8')\n",
    "                print(loss_value22,file=log3)\n",
    "                log3.close()\n",
    "                \n",
    "                \n",
    "\n",
    "        self.optimizer.minimize(self.sess, \n",
    "                                feed_dict = tf_dict, \n",
    "                                fetches = [self.loss,self.f_u_pred,self.u0_pred,self.u_ub_pred,self.u_lb_pred], \n",
    "                                loss_callback = self.callback\n",
    "                               )    \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        self.optimizer11.minimize(self.sess, \n",
    "                                feed_dict = tf_dict, \n",
    "                                fetches = [self.lossss,self.f_u_pred,self.u0_pred,self.u_ub_pred,self.u_lb_pred], \n",
    "                                loss_callback = self.callback11\n",
    "                               )  \n",
    "        \n",
    "        \n",
    "      \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.optimizer22.minimize(self.sess, \n",
    "                                feed_dict = tf_dict, \n",
    "                                fetches = [self.lossss33,self.f_u_pred,self.u0_pred,self.u_ub_pred,self.u_lb_pred], \n",
    "                                loss_callback = self.callback22\n",
    "                               )         \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        return lossloss1,lossloss2\n",
    "    \n",
    "    def predict(self, X_star):\n",
    "        \n",
    "        tf_dict = {self.x0_tf: X_star[:,0:1], self.t0_tf: X_star[:,1:2]}\n",
    "        \n",
    "        u_star = self.sess.run(self.u0_pred, tf_dict)  \n",
    "        \n",
    "        \n",
    "        tf_dict = {self.x_f_tf: X_star[:,0:1], self.t_f_tf: X_star[:,1:2]}\n",
    "        \n",
    "        f_u_star = self.sess.run(self.f_u_pred, tf_dict)\n",
    "               \n",
    "        return u_star,f_u_star\n",
    "    def loss_show(self):\n",
    "        return self.losslossloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b938223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatsolution(x,t):\n",
    "    return math.exp(1/((2*t-1)**2+0.3))*(1-x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfbb4bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "         \n",
    "    \n",
    "    # Doman bounds\n",
    "    lb = np.array([-1, 0])\n",
    "    ub = np.array([1, 1])\n",
    "\n",
    "    N0 = 700                                      #初始点\n",
    "    N_b = 700                                     #边界点\n",
    "    N_f = 3000                              #适配点\n",
    "    layers = [2,20,20,20,20,1]  \n",
    "    #读取真实解\n",
    "    x=np.linspace(-1,1,700).flatten()[:,None]   \n",
    "    t=np.linspace(0,1,700).flatten()[:,None]   \n",
    "    res=np.zeros([len(x),len(t)])  \n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(t)):\n",
    "            res[i,j]=heatsolution(x[i],t[j])\n",
    "    \n",
    "    \n",
    "    X, T = np.meshgrid(x, t)\n",
    "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "    #选定初始点N0=700个点\n",
    "    idx_x = np.random.choice(x.shape[0], N0, replace=False)   \n",
    "    x0 = x[idx_x,:]\n",
    "    u0 = res[idx_x,0:1]\n",
    "    #选择N_b=700个边界点\n",
    "    idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "    tb = t[idx_t,:]\n",
    "    u_lb = res[0,idx_t]\n",
    "    u_ub=res[-1,idx_t]\n",
    "    #N_f=2500个随机搭配点   第一列位置 第二列时间\n",
    "    X_f = lb + (ub-lb)*lhs(2, N_f)\n",
    "    x0=np.array(x0).flatten()[:,None]\n",
    "    u0=np.array(u0).flatten()[:,None]\n",
    "    u_lb=np.array(u_lb).flatten()[:,None]\n",
    "    u_ub=np.array(u_ub).flatten()[:,None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44e1cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = PhysicsInformedNN(x0, u0,tb, X_f, layers, lb, ub,u_lb,u_ub)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a25234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, Loss1: 1.944436908e+00,loss2: 9.012189507e-02 Loss3: 3.144972900e+03,Time: 0.77\n",
      "It: 200, Loss1: 3.580900375e-03,loss2: 2.056691796e-02 Loss3: 3.089749756e+03,Time: 1.24\n",
      "It: 400, Loss1: 1.683206484e-02,loss2: 1.253285110e-01 Loss3: 2.254687256e+03,Time: 1.15\n",
      "It: 600, Loss1: 8.921913803e-03,loss2: 2.464210615e-02 Loss3: 3.181157532e+02,Time: 1.24\n",
      "It: 800, Loss1: 1.057190914e-02,loss2: 3.221362457e-02 Loss3: 4.410839462e+01,Time: 1.19\n",
      "It: 1000, Loss1: 4.633031785e-03,loss2: 3.627748787e-02 Loss3: 7.624771595e-01,Time: 1.13\n",
      "It: 1200, Loss1: 2.489450388e-03,loss2: 1.472806744e-02 Loss3: 1.750537902e-01,Time: 1.10\n",
      "It: 1400, Loss1: 2.126625506e-03,loss2: 1.232984755e-02 Loss3: 9.942890704e-02,Time: 1.13\n",
      "It: 1600, Loss1: 2.396506490e-03,loss2: 9.898146614e-03 Loss3: 7.232839614e-02,Time: 1.09\n",
      "It: 1800, Loss1: 2.234810498e-03,loss2: 9.006418288e-03 Loss3: 5.674581975e-02,Time: 1.14\n",
      "It: 200, Loss1: 4.635444842e-03,loss2: 7.834624499e-03 Loss3: 5.950930063e-03\n",
      "It: 400, Loss1: 3.401400289e-03,loss2: 8.099446073e-03 Loss3: 3.132638987e-03\n",
      "It: 600, Loss1: 2.319555962e-03,loss2: 7.820441388e-03 Loss3: 1.895907451e-03\n",
      "It: 800, Loss1: 1.083396957e-03,loss2: 7.965400815e-03 Loss3: 1.289385371e-03\n",
      "It: 1000, Loss1: 6.076378631e-04,loss2: 7.755835541e-03 Loss3: 9.840778075e-04\n",
      "It: 1200, Loss1: 4.498504277e-04,loss2: 6.604458205e-03 Loss3: 7.805922069e-04\n",
      "It: 1400, Loss1: 1.955014304e-04,loss2: 5.066711456e-03 Loss3: 5.968165933e-04\n",
      "It: 1600, Loss1: 1.566927531e-04,loss2: 3.995344508e-03 Loss3: 4.749011132e-04\n",
      "It: 1800, Loss1: 2.145120525e-04,loss2: 3.462894354e-03 Loss3: 4.111130256e-04\n",
      "It: 2000, Loss1: 2.157667914e-04,loss2: 3.130091121e-03 Loss3: 3.475368139e-04\n",
      "It: 2200, Loss1: 2.235871070e-04,loss2: 3.332956228e-03 Loss3: 2.863347472e-04\n",
      "It: 2400, Loss1: 3.741379187e-04,loss2: 3.353081178e-03 Loss3: 2.345818211e-04\n",
      "It: 2600, Loss1: 5.047918530e-04,loss2: 3.402843839e-03 Loss3: 1.952908497e-04\n",
      "It: 2800, Loss1: 2.088310721e-04,loss2: 3.749502823e-03 Loss3: 1.663934236e-04\n",
      "It: 3000, Loss1: 1.318798604e-04,loss2: 3.767268732e-03 Loss3: 1.441437053e-04\n",
      "It: 3200, Loss1: 1.718083804e-04,loss2: 3.458115272e-03 Loss3: 1.314587571e-04\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.054270\n",
      "  Number of iterations: 3046\n",
      "  Number of functions evaluations: 3236\n",
      "It: 3240, Loss1: 1.655012748e-04,loss2: 3.388756886e-03 Loss3: 1.304859761e-04\n",
      "It: 3260, Loss1: 1.654605876e-04,loss2: 3.388230689e-03 Loss3: 1.308489882e-04\n",
      "It: 3280, Loss1: 1.654905791e-04,loss2: 3.388844896e-03 Loss3: 1.304362959e-04\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.014975\n",
      "  Number of iterations: 2\n",
      "  Number of functions evaluations: 44\n",
      "It: 3300, Loss1: 1.169992101e-04,loss2: 3.085281933e-03 Loss3: 2.688494860e-04\n",
      "It: 3320, Loss1: 5.454878192e-05,loss2: 2.291244455e-03 Loss3: 4.324514885e-04\n",
      "It: 3340, Loss1: 1.724261710e-05,loss2: 1.854055678e-03 Loss3: 5.297850585e-04\n",
      "It: 3360, Loss1: 8.759933735e-06,loss2: 1.782108215e-03 Loss3: 4.267292097e-04\n",
      "It: 3380, Loss1: 9.161131857e-06,loss2: 1.670334488e-03 Loss3: 3.419900022e-04\n",
      "It: 3400, Loss1: 8.240067473e-06,loss2: 1.596058719e-03 Loss3: 3.173265432e-04\n",
      "It: 3420, Loss1: 3.948701305e-06,loss2: 1.542570069e-03 Loss3: 3.107411903e-04\n",
      "It: 3440, Loss1: 3.854228453e-06,loss2: 1.454608049e-03 Loss3: 3.179191262e-04\n",
      "It: 3460, Loss1: 3.425049272e-06,loss2: 1.387655269e-03 Loss3: 3.288217995e-04\n",
      "It: 3480, Loss1: 4.636489848e-06,loss2: 1.342811855e-03 Loss3: 3.199065977e-04\n",
      "It: 3500, Loss1: 4.560078651e-06,loss2: 1.301468001e-03 Loss3: 3.211567237e-04\n",
      "It: 3520, Loss1: 3.362319376e-06,loss2: 1.270560664e-03 Loss3: 3.234265605e-04\n",
      "It: 3540, Loss1: 6.238227343e-06,loss2: 1.211677212e-03 Loss3: 3.168954863e-04\n",
      "It: 3560, Loss1: 7.001306585e-06,loss2: 1.174972393e-03 Loss3: 3.207416739e-04\n",
      "It: 3580, Loss1: 5.256842996e-06,loss2: 1.129308948e-03 Loss3: 3.094883286e-04\n",
      "It: 3600, Loss1: 1.738694095e-06,loss2: 1.060367911e-03 Loss3: 3.261821694e-04\n",
      "It: 3620, Loss1: 8.002234608e-07,loss2: 1.016836148e-03 Loss3: 3.434975515e-04\n",
      "It: 3640, Loss1: 9.128826264e-07,loss2: 9.962482145e-04 Loss3: 3.134300641e-04\n",
      "It: 3660, Loss1: 3.039787089e-06,loss2: 9.658589843e-04 Loss3: 3.094374842e-04\n",
      "It: 3680, Loss1: 2.889014468e-06,loss2: 9.025778854e-04 Loss3: 3.254639741e-04\n",
      "It: 3700, Loss1: 2.851264753e-06,loss2: 8.599566063e-04 Loss3: 3.425953328e-04\n",
      "It: 3720, Loss1: 5.111013706e-06,loss2: 8.277917514e-04 Loss3: 3.482842585e-04\n",
      "It: 3740, Loss1: 6.955666322e-06,loss2: 7.883810904e-04 Loss3: 3.406818723e-04\n",
      "It: 3760, Loss1: 2.716844847e-06,loss2: 7.524486282e-04 Loss3: 3.465986229e-04\n",
      "It: 3780, Loss1: 1.803735017e-06,loss2: 7.212061901e-04 Loss3: 3.565299558e-04\n",
      "It: 3800, Loss1: 2.364057991e-06,loss2: 7.011679700e-04 Loss3: 3.447372001e-04\n",
      "It: 3820, Loss1: 2.736122042e-06,loss2: 6.586385425e-04 Loss3: 3.579793265e-04\n",
      "It: 3840, Loss1: 1.203173156e-06,loss2: 6.319498643e-04 Loss3: 3.569291148e-04\n",
      "It: 3860, Loss1: 1.927676067e-06,loss2: 6.083832122e-04 Loss3: 3.473154793e-04\n",
      "It: 3880, Loss1: 1.931503448e-06,loss2: 5.714097060e-04 Loss3: 3.582561039e-04\n",
      "It: 3900, Loss1: 2.249708359e-06,loss2: 5.512167118e-04 Loss3: 3.580847115e-04\n",
      "It: 3920, Loss1: 2.591604698e-06,loss2: 5.517023965e-04 Loss3: 3.470529045e-04\n",
      "It: 3940, Loss1: 2.857408390e-06,loss2: 5.441810936e-04 Loss3: 3.434699320e-04\n",
      "It: 3960, Loss1: 4.521253686e-06,loss2: 5.236510769e-04 Loss3: 3.491884854e-04\n",
      "It: 3980, Loss1: 4.736150004e-06,loss2: 5.100882845e-04 Loss3: 3.509270027e-04\n",
      "It: 4000, Loss1: 4.585350325e-06,loss2: 4.978095531e-04 Loss3: 3.476073616e-04\n",
      "It: 4020, Loss1: 5.575820069e-06,loss2: 4.813152482e-04 Loss3: 3.497759462e-04\n",
      "It: 4040, Loss1: 4.357059879e-06,loss2: 4.653946380e-04 Loss3: 3.551563423e-04\n",
      "It: 4060, Loss1: 5.817156762e-06,loss2: 4.496044421e-04 Loss3: 3.538793826e-04\n",
      "It: 4080, Loss1: 5.549227353e-06,loss2: 4.344087210e-04 Loss3: 3.571625857e-04\n",
      "It: 4100, Loss1: 6.045982445e-06,loss2: 4.051847500e-04 Loss3: 3.651713487e-04\n",
      "It: 4120, Loss1: 7.084045137e-06,loss2: 3.975400177e-04 Loss3: 3.630966239e-04\n",
      "It: 4140, Loss1: 5.768774827e-06,loss2: 3.932755208e-04 Loss3: 3.545513027e-04\n",
      "It: 4160, Loss1: 5.891414730e-06,loss2: 3.842244041e-04 Loss3: 3.482530010e-04\n",
      "It: 4180, Loss1: 3.075483619e-06,loss2: 3.764650028e-04 Loss3: 3.437505511e-04\n",
      "It: 4200, Loss1: 3.772989885e-06,loss2: 3.555110889e-04 Loss3: 3.402227303e-04\n",
      "It: 4220, Loss1: 4.697680197e-06,loss2: 3.428725759e-04 Loss3: 3.317186784e-04\n",
      "It: 4240, Loss1: 5.055465863e-06,loss2: 3.314865171e-04 Loss3: 3.345247824e-04\n",
      "It: 4260, Loss1: 3.976061180e-06,loss2: 3.184892703e-04 Loss3: 3.388727200e-04\n",
      "It: 4280, Loss1: 4.452827397e-06,loss2: 3.124344512e-04 Loss3: 3.369914775e-04\n",
      "It: 4300, Loss1: 4.749887012e-06,loss2: 2.938340476e-04 Loss3: 3.405371390e-04\n",
      "It: 4320, Loss1: 6.470617791e-06,loss2: 2.790861181e-04 Loss3: 3.467941424e-04\n",
      "It: 4340, Loss1: 7.954319699e-06,loss2: 2.785683027e-04 Loss3: 3.373546642e-04\n",
      "It: 4360, Loss1: 8.279347639e-06,loss2: 2.796982590e-04 Loss3: 3.263539984e-04\n",
      "It: 4380, Loss1: 9.829276678e-06,loss2: 2.772558364e-04 Loss3: 3.217523335e-04\n",
      "It: 4400, Loss1: 9.351218978e-06,loss2: 2.643503249e-04 Loss3: 3.246816341e-04\n",
      "It: 4420, Loss1: 1.010004416e-05,loss2: 2.551014186e-04 Loss3: 3.244506079e-04\n",
      "It: 4440, Loss1: 1.042520944e-05,loss2: 2.464105783e-04 Loss3: 3.260159865e-04\n",
      "It: 4460, Loss1: 8.841323506e-06,loss2: 2.329429844e-04 Loss3: 3.295753268e-04\n",
      "It: 4480, Loss1: 7.338990144e-06,loss2: 2.246642252e-04 Loss3: 3.274533374e-04\n",
      "It: 4500, Loss1: 7.066439139e-06,loss2: 2.256644657e-04 Loss3: 3.201775253e-04\n",
      "It: 4520, Loss1: 5.502446129e-06,loss2: 2.266800584e-04 Loss3: 3.145361843e-04\n",
      "It: 4540, Loss1: 4.962022103e-06,loss2: 2.200183226e-04 Loss3: 3.140261979e-04\n",
      "It: 4560, Loss1: 4.141807494e-06,loss2: 2.213069529e-04 Loss3: 3.036029520e-04\n",
      "It: 4580, Loss1: 3.560415962e-06,loss2: 2.172676905e-04 Loss3: 2.989214554e-04\n",
      "It: 4600, Loss1: 4.048558822e-06,loss2: 2.121347352e-04 Loss3: 2.979055280e-04\n",
      "It: 4620, Loss1: 4.093666121e-06,loss2: 2.045000583e-04 Loss3: 3.005329345e-04\n",
      "It: 4640, Loss1: 3.822194230e-06,loss2: 1.990031451e-04 Loss3: 2.994418901e-04\n",
      "It: 4660, Loss1: 2.917137863e-06,loss2: 1.944083633e-04 Loss3: 2.972573857e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 4680, Loss1: 3.393994803e-06,loss2: 1.899614581e-04 Loss3: 2.955815871e-04\n",
      "It: 4700, Loss1: 3.434385690e-06,loss2: 1.792440016e-04 Loss3: 2.983795712e-04\n",
      "It: 4720, Loss1: 2.786322057e-06,loss2: 1.765482593e-04 Loss3: 2.937607642e-04\n",
      "It: 4740, Loss1: 2.683530965e-06,loss2: 1.709592470e-04 Loss3: 2.929671900e-04\n",
      "It: 4760, Loss1: 1.834525733e-06,loss2: 1.710232609e-04 Loss3: 2.878755040e-04\n",
      "It: 4780, Loss1: 2.423539172e-06,loss2: 1.679534325e-04 Loss3: 2.857187064e-04\n",
      "It: 4800, Loss1: 2.685399750e-06,loss2: 1.651534549e-04 Loss3: 2.844934352e-04\n",
      "It: 4820, Loss1: 2.533409543e-06,loss2: 1.645855955e-04 Loss3: 2.808104036e-04\n",
      "It: 4840, Loss1: 2.938454827e-06,loss2: 1.614719367e-04 Loss3: 2.802492527e-04\n",
      "It: 4860, Loss1: 2.986165782e-06,loss2: 1.593789202e-04 Loss3: 2.783267119e-04\n",
      "It: 4880, Loss1: 2.928610684e-06,loss2: 1.577814692e-04 Loss3: 2.751730790e-04\n",
      "It: 4900, Loss1: 3.032488166e-06,loss2: 1.568043954e-04 Loss3: 2.717993630e-04\n",
      "It: 4920, Loss1: 2.485850700e-06,loss2: 1.567308645e-04 Loss3: 2.669414389e-04\n",
      "It: 4940, Loss1: 2.805099712e-06,loss2: 1.441411732e-04 Loss3: 2.712630667e-04\n",
      "It: 4960, Loss1: 3.287978871e-06,loss2: 1.380735775e-04 Loss3: 2.731214045e-04\n",
      "It: 4980, Loss1: 3.125533112e-06,loss2: 1.353933185e-04 Loss3: 2.687509987e-04\n",
      "It: 5000, Loss1: 3.082830062e-06,loss2: 1.334003755e-04 Loss3: 2.649386588e-04\n",
      "It: 5020, Loss1: 3.133742894e-06,loss2: 1.351902611e-04 Loss3: 2.580450964e-04\n",
      "It: 5040, Loss1: 3.867891337e-06,loss2: 1.312383974e-04 Loss3: 2.555482788e-04\n",
      "It: 5060, Loss1: 4.019193057e-06,loss2: 1.272328082e-04 Loss3: 2.520655980e-04\n",
      "It: 5080, Loss1: 3.387611287e-06,loss2: 1.208444883e-04 Loss3: 2.530837082e-04\n",
      "It: 5100, Loss1: 2.650439228e-06,loss2: 1.197081438e-04 Loss3: 2.510914055e-04\n",
      "It: 5120, Loss1: 2.254320179e-06,loss2: 1.182744527e-04 Loss3: 2.479225805e-04\n",
      "It: 5140, Loss1: 2.031072881e-06,loss2: 1.160677639e-04 Loss3: 2.465209982e-04\n",
      "It: 5160, Loss1: 1.982996309e-06,loss2: 1.141061584e-04 Loss3: 2.444200509e-04\n",
      "It: 5180, Loss1: 2.630301651e-06,loss2: 1.111878373e-04 Loss3: 2.416827483e-04\n",
      "It: 5200, Loss1: 3.024598527e-06,loss2: 1.079181966e-04 Loss3: 2.392214519e-04\n",
      "It: 5220, Loss1: 3.368945272e-06,loss2: 1.067900885e-04 Loss3: 2.371841401e-04\n",
      "It: 5240, Loss1: 3.553138640e-06,loss2: 1.030581334e-04 Loss3: 2.346418769e-04\n",
      "It: 5260, Loss1: 4.042007276e-06,loss2: 1.027071776e-04 Loss3: 2.303662041e-04\n",
      "It: 5280, Loss1: 3.977515917e-06,loss2: 9.932488319e-05 Loss3: 2.287007956e-04\n",
      "It: 5300, Loss1: 4.270153113e-06,loss2: 1.018089388e-04 Loss3: 2.211021783e-04\n",
      "It: 5320, Loss1: 3.819891845e-06,loss2: 9.997312736e-05 Loss3: 2.192287793e-04\n",
      "It: 5340, Loss1: 3.651353154e-06,loss2: 9.945325291e-05 Loss3: 2.168333594e-04\n",
      "It: 5360, Loss1: 3.904221103e-06,loss2: 9.661554941e-05 Loss3: 2.170983935e-04\n",
      "It: 5380, Loss1: 3.601244089e-06,loss2: 9.555253200e-05 Loss3: 2.167897765e-04\n",
      "It: 5400, Loss1: 3.929874310e-06,loss2: 9.113224223e-05 Loss3: 2.162921446e-04\n",
      "It: 5420, Loss1: 3.254290505e-06,loss2: 8.832707681e-05 Loss3: 2.166295890e-04\n",
      "It: 5440, Loss1: 2.711228262e-06,loss2: 8.740689373e-05 Loss3: 2.125791507e-04\n",
      "It: 5460, Loss1: 2.541481535e-06,loss2: 8.513955254e-05 Loss3: 2.118930424e-04\n",
      "It: 5480, Loss1: 1.787170049e-06,loss2: 8.124446322e-05 Loss3: 2.114772069e-04\n",
      "It: 5500, Loss1: 1.273518023e-06,loss2: 7.966485282e-05 Loss3: 2.089437912e-04\n",
      "It: 5520, Loss1: 1.288370981e-06,loss2: 7.809093950e-05 Loss3: 2.057971142e-04\n",
      "It: 5540, Loss1: 1.423586468e-06,loss2: 7.456476305e-05 Loss3: 2.052185155e-04\n",
      "It: 5560, Loss1: 1.656452696e-06,loss2: 7.180155080e-05 Loss3: 2.036870719e-04\n",
      "It: 5580, Loss1: 1.792473199e-06,loss2: 7.020471821e-05 Loss3: 2.026761940e-04\n",
      "It: 5600, Loss1: 2.059457984e-06,loss2: 6.984608626e-05 Loss3: 2.009120799e-04\n",
      "It: 5620, Loss1: 2.365847422e-06,loss2: 6.944911729e-05 Loss3: 1.991111058e-04\n",
      "It: 5640, Loss1: 2.455700042e-06,loss2: 6.798873073e-05 Loss3: 1.985132840e-04\n",
      "It: 5660, Loss1: 2.434763246e-06,loss2: 6.641558866e-05 Loss3: 1.978727232e-04\n",
      "It: 5680, Loss1: 2.195913567e-06,loss2: 6.282170943e-05 Loss3: 1.973506878e-04\n",
      "It: 5700, Loss1: 2.142891844e-06,loss2: 6.102312182e-05 Loss3: 1.965514093e-04\n",
      "It: 5720, Loss1: 2.341575055e-06,loss2: 6.005469550e-05 Loss3: 1.946793636e-04\n",
      "It: 5740, Loss1: 2.196617515e-06,loss2: 6.009088611e-05 Loss3: 1.922237716e-04\n",
      "It: 5760, Loss1: 2.320947033e-06,loss2: 6.003196540e-05 Loss3: 1.899643394e-04\n",
      "It: 5780, Loss1: 2.442479172e-06,loss2: 5.891303590e-05 Loss3: 1.873030269e-04\n",
      "It: 5800, Loss1: 2.366388799e-06,loss2: 5.813142343e-05 Loss3: 1.859588665e-04\n",
      "It: 5820, Loss1: 1.972281780e-06,loss2: 5.697185406e-05 Loss3: 1.859319455e-04\n",
      "It: 5840, Loss1: 1.649443789e-06,loss2: 5.567914923e-05 Loss3: 1.851384295e-04\n",
      "It: 5860, Loss1: 2.001673010e-06,loss2: 5.355918256e-05 Loss3: 1.834471623e-04\n",
      "It: 5880, Loss1: 2.267130185e-06,loss2: 5.349015555e-05 Loss3: 1.808055240e-04\n",
      "It: 5900, Loss1: 2.352137926e-06,loss2: 5.373765453e-05 Loss3: 1.785904897e-04\n",
      "It: 5920, Loss1: 2.364464081e-06,loss2: 5.348309060e-05 Loss3: 1.770883391e-04\n",
      "It: 5940, Loss1: 2.512109177e-06,loss2: 5.231873729e-05 Loss3: 1.752491953e-04\n",
      "It: 5960, Loss1: 2.530325219e-06,loss2: 5.309922199e-05 Loss3: 1.729297801e-04\n",
      "It: 5980, Loss1: 2.314804988e-06,loss2: 5.166744086e-05 Loss3: 1.722313173e-04\n",
      "It: 6000, Loss1: 1.818995884e-06,loss2: 5.004848208e-05 Loss3: 1.706272888e-04\n",
      "It: 6020, Loss1: 1.495159609e-06,loss2: 4.854445069e-05 Loss3: 1.689699857e-04\n",
      "It: 6040, Loss1: 1.588847567e-06,loss2: 4.772418470e-05 Loss3: 1.685185998e-04\n",
      "It: 6060, Loss1: 1.482985226e-06,loss2: 4.814314889e-05 Loss3: 1.665161981e-04\n",
      "It: 6080, Loss1: 1.394168635e-06,loss2: 4.729831926e-05 Loss3: 1.643326541e-04\n",
      "It: 6100, Loss1: 1.482216476e-06,loss2: 4.583650298e-05 Loss3: 1.633450447e-04\n",
      "It: 6120, Loss1: 1.341451252e-06,loss2: 4.459493357e-05 Loss3: 1.620815310e-04\n",
      "It: 6140, Loss1: 1.436495722e-06,loss2: 4.385946522e-05 Loss3: 1.607060258e-04\n",
      "It: 6160, Loss1: 1.325692324e-06,loss2: 4.347863432e-05 Loss3: 1.594170899e-04\n",
      "It: 6180, Loss1: 1.338533821e-06,loss2: 4.267319673e-05 Loss3: 1.581848774e-04\n",
      "It: 6200, Loss1: 1.132953116e-06,loss2: 4.265317693e-05 Loss3: 1.561576064e-04\n",
      "It: 6220, Loss1: 1.038472760e-06,loss2: 4.160331082e-05 Loss3: 1.554990158e-04\n",
      "It: 6240, Loss1: 1.086781822e-06,loss2: 4.136650386e-05 Loss3: 1.540843659e-04\n",
      "It: 6260, Loss1: 1.226878226e-06,loss2: 4.159622040e-05 Loss3: 1.527212589e-04\n",
      "It: 6280, Loss1: 1.262661499e-06,loss2: 4.092963354e-05 Loss3: 1.525195694e-04\n",
      "It: 6300, Loss1: 1.008460799e-06,loss2: 4.005412484e-05 Loss3: 1.522729581e-04\n",
      "It: 6320, Loss1: 8.900360626e-07,loss2: 3.880679287e-05 Loss3: 1.521899831e-04\n",
      "It: 6340, Loss1: 8.005806649e-07,loss2: 3.872514935e-05 Loss3: 1.511017326e-04\n",
      "It: 6360, Loss1: 7.823639976e-07,loss2: 3.850547728e-05 Loss3: 1.504844258e-04\n",
      "It: 6380, Loss1: 7.163243367e-07,loss2: 3.861826553e-05 Loss3: 1.491177973e-04\n",
      "It: 6400, Loss1: 6.910619277e-07,loss2: 3.867035412e-05 Loss3: 1.479710045e-04\n",
      "It: 6420, Loss1: 6.805273642e-07,loss2: 3.770342300e-05 Loss3: 1.475302270e-04\n",
      "It: 6440, Loss1: 6.200740472e-07,loss2: 3.637601185e-05 Loss3: 1.479008642e-04\n",
      "It: 6460, Loss1: 5.582099902e-07,loss2: 3.532284245e-05 Loss3: 1.478275517e-04\n",
      "It: 6480, Loss1: 5.970043162e-07,loss2: 3.462887616e-05 Loss3: 1.476185716e-04\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 0.000183\n",
      "  Number of iterations: 2962\n",
      "  Number of functions evaluations: 3213\n"
     ]
    }
   ],
   "source": [
    "LOSS1,LOSS2=model.train(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bbf95ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "二范数Error u: 1.610665e-04\n",
      "平均绝对Error u: 8.656940e-04\n",
      "无穷范数Error u: 2.147657e-02\n"
     ]
    }
   ],
   "source": [
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_pred, f_u_pred = model.predict(X_star)\n",
    "u_star = res.T.flatten()[:,None]  \n",
    "error_u1 = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "error_u2 = np.linalg.norm(u_star-u_pred,1)/len(u_star)\n",
    "error_u3 = np.linalg.norm(u_star-u_pred,np.inf)\n",
    "print('二范数Error u: %e' % (error_u1))\n",
    "print('平均绝对Error u: %e' % (error_u2))\n",
    "print('无穷范数Error u: %e' % (error_u3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e2e6354",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"f_u.mat\", {'f_u': f_u_pred})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbff7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695b2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d98f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c224b63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfcpu",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
